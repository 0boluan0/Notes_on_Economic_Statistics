
#  **分布滞后模型Distributed Lag Model DLM**

## 含义

分布滞后模型是静态模型.但是它反映了解释变量的动态影像

分布滞后模型（Distributed Lag Model, DLM）是一种时间序列模型，用于描述当前因变量不仅受当前解释变量的影响，还受其过去若干期的解释变量的影响。分布滞后模型广泛用于经济学、金融学等领域，分析变量之间的动态关系。

## **分布滞后模型的基本形式**

假设我们有一个时间序列模型，其中因变量 $Y_t$ 受解释变量 $X_t$ 及其过去若干期的值 $X_{t-1}, X_{t-2}, \ldots, X_{t-q}$ 的影响。分布滞后模型可以表示为：

$$ Y_t = \alpha + \beta_0 X_t + \beta_1 X_{t-1} + \beta_2 X_{t-2} + \cdots + \beta_q X_{t-q} + \epsilon_t $$

其中：

• $Y_t$ 是时间 $t$ 的因变量。
• $X_t, X_{t-1}, \ldots, X_{t-q}$ 是时间 $t$ 及其之前若干期的解释变量。
• $\alpha$ 是常数项。
• $\beta_0, \beta_1, \beta_2, \ldots, \beta_q$ 是滞后期的系数。至于具体选多少项,使用信息准则来选择.但是如果使用信息准则算出来的最后一项的符号跟先前相反,那就不合理,此时虽然统计学上好,但是经济学上烂,把它丢掉算了. 
• $\epsilon_t$ 是误差项，假设其期望为0且方差恒定。

## **分布滞后模型的特性**

1. **短期乘数**：当前期的解释变量对因变量的影响，由$\beta_0$ 表示。
2. **中期乘数**:如果此后x的变化都保持在同一水平上，y的变化可以由$beta$加和得到,叫中期乘数.
3. **长期乘数**：所有滞后期的解释变量对因变量的总影响，由 $\beta_0 + \beta_1 + \beta_2 + \cdots + \beta_q$ 表示。
4. **滞后分布**：滞后系数 $\beta_0, \beta_1, \beta_2, \ldots, \beta_q$ 描述了解释变量对因变量的动态影响。加起来不能趋于无穷大,不然不收敛.这也意味着解释变量对被解释变量的长期影响是有限的,且随时间推移减小.

## **分布滞后模型的估计**

分布滞后模型的参数通常通过最小二乘法（OLS）估计。

# 自回归分布滞后模型

分布滞后模型的基本形式为：
$$ Y_t = \alpha + \beta_0 X_t + \beta_1 X_{t-1} + \beta_2 X_{t-2} + \cdots + \beta_q X_{t-q} + \epsilon_t $$
在这个模型中，$Y_t$ 受到解释变量 $X_t$ 以及其滞后值 $X_{t-1}, X_{t-2}, \ldots, X_{t-q}$ 的影响。这意味着模型捕捉了 $X$ 对 $Y$ 的时间滞后效应，是一个典型的动态模型。

## 适应性预期模型

### **适应性预期模型的基本原理**

适应性预期模型的核心思想是，经济主体的预期会随着实际结果的变化而逐步调整。具体来说，经济主体会根据实际结果与之前预期之间的误差来修正他们的预期。适应性预期模型基于经济理论基础，认为经济活动主体是根据他们对某些经济变量的“预期”做出决策的。其核心思想是：影响yt的因素不是xt ，而是对xt 的预期 xt* .

如果预测不准,就会用预测差值乘上$\lambda$放到下一期来修正预期值.

### **数学形式**

假设 $P_t$ 表示时间 $t$ 的实际值（例如价格水平），$P_t^e$ 表示时间 $t$ 对价格水平的预期值。适应性预期模型可以表示为  

$$ P_t^e = P_{t-1}^e + \lambda (P_{t-1} - P_{t-1}^e) $$

其中：

• $P_t^e$ 是时间 $t$ 对价格水平的预期值。
• $P_{t-1}^e$ 是时间 $t-1$ 对价格水平的预期值。
• $P_{t-1}$ 是时间 $t-1$ 的实际价格水平。
• $\lambda$ 是调整系数，$0 < \lambda \leq 1$。

## 部分调整模型

部分调整模型是一种用于描述经济变量如何随着时间逐步调整到目标水平的动态模型。这种模型假设经济变量不会立即调整到其长期均衡水平，而是逐步地进行调整。部分调整模型广泛应用于经济学中的投资、消费、工资和价格等领域。

### **部分调整模型的基本原理**

部分调整模型的核心思想是，经济变量在每个时期只进行部分调整，逐步接近其长期目标值。调整速度由调整系数决定。

### **数学形式**

假设 $Y_t$ 是时间 $t$ 的实际值，$Y_t^*$ 是时间 $t$ 的目标值，部分调整模型可以表示为：

$$ Y_t - Y_{t-1} = \lambda (Y_t^* - Y_{t-1}) $$

其中：

• $Y_t$ 是时间 $t$ 的实际值。
• $Y_t^*$ 是时间 $t$ 的目标值。
• $Y_{t-1}$ 是时间 $t-1$ 的实际值。
• $\lambda$ 是调整系数，$0 < \lambda \leq 1$。

这个公式可以重新排列为:  

$$ Y_t = (1 - \lambda)Y_{t-1} + \lambda Y_t^* $$

### **解释**

1. **调整速度**：
• $\lambda$ 表示调整速度。$\lambda$ 越接近1，调整越快；$\lambda$ 越接近0，调整越慢。
• 当 $\lambda = 1$ 时，实际值在一个时期内完全调整到目标值；当 $\lambda = 0$ 时，实际值完全没有调整。

2. **逐步调整**：
• 经济变量逐步调整到其长期目标值，反映了现实中经济变量调整过程中存在的摩擦、成本和惯性。

###  **目标值的确定**

  目标值 $Y_t^*$ 通常取决于模型中其他变量。例如，在投资模型中，目标投资水平可能取决于预期的未来收益。在工资调整模型中，目标工资水平可能取决于通货膨胀率和劳动生产率。

## 自回归分布滞后模型的估计

OLS有偏,严格外生不可能满足,残差项无自相关时才满足若外生.使用工具变量或两阶段最小二乘法计算.

### 德宾h检验

动态模型中如果有自相关,估计出来的就是有偏非一致的,所以DW统计里那个没法用.用这个新的h统计量

#### **数学原理**

假设我们有一个线性回归模型：

$$ Y_t = \beta_0 + \beta_1 X_t + \beta_2 Y_{t-1} + \epsilon_t $$

其中，$Y_{t-1}$ 是因变量的滞后项，$\epsilon_t$ 是误差项。我们关心误差项 $\epsilon_t$ 是否存在自相关，即是否 $\epsilon_t$ 与 $\epsilon_{t-1}$ 相关。

德宾 h 检验的原理是基于估计残差的自相关性。假设误差项 $\epsilon_t$ 满足以下自回归模型：

$$ \epsilon_t = \rho \epsilon_{t-1} + u_t $$

其中，$\rho$ 是自相关系数，$u_t$ 是白噪声。

#### **德宾 h 统计量**

德宾 h 统计量定义为：

$$ h = (1 - \frac{1}{2} d) \sqrt{\frac{n}{1 - n \text{Var}(\hat{\beta_2})}} =\hat\rho \sqrt{\frac{n}{1 - n \text{Var}(\hat{\beta_2})}} $$  
其中：

• $d$ 是德宾-沃森统计量。
• $n$ 是样本量。
• $\text{Var}(\hat{\beta_2})$ 是回归模型中滞后自变量 $Y_{t-1}$ 的系数 $\beta_2$ 的方差。

==注意:==

* 根号里面不能是负的,不然无意义,h检验无效.
* 如果包含多个解释变量和多个值哦呼被解释变量也是有效的.

#### **计算步骤**

1. **估计回归模型**：
使用普通最小二乘法（OLS）估计回归模型，得到回归系数和残差。

2. **计算德宾-沃森统计量**：
德宾-沃森统计量 $d$ 的计算公式为：
$$ d = \frac{\sum_{t=2}^{n} (e_t - e_{t-1})^2}{\sum_{t=1}^{n} e_t^2} $$
其中，$e_t$ 是残差。

3. **计算 $\text{Var}(\hat{\beta_2})$**：

通过 OLS 回归结果得到 $\beta_2$ 的方差估计值。

4. **计算德宾 h 统计量**：

使用上述公式计算德宾 h 统计量。

5. **进行假设检验**：

• 原假设 $H_0$：$\rho = 0$（没有自相关）。
• 备择假设 $H_1$：$\rho \neq 0$（存在自相关）。
如果 $|h| > 1.96$，在 5% 的显著性水平下拒绝原假设，认为存在显著的自相关。

### 工具变量估计法

给滞后的因变量找它的解释变量做工具变量,然后进行两阶段最小二乘估计.

# ARMA模型

## 时间序列分析的几个基本概念

### 随机过程

就是随机变量在时间序列的表现,每个点都有它自己的期望,方差,均值啥的

### 白噪声过程

一种特殊的随机过程,均值是0,方差是个常数.任意时点之间协方差为0.

### 平稳随机过程

均值和方差在时间上是常数,任何两期之间协方差只和两期的间隔有关,和实际时间不相关,就是平稳随机过程.

###  自相关函数

期望和方差均为常数,滞后k期的自协方差就是相隔k期的两个随机变量的协方差.k=0时就是方差.

### 偏自相关函数

相当于偏效应,排除掉其他期的影响之后,仅研究某一期对当期的影响.但是在经济中很难识别,因为数据很难拿到.

## AR自回归模型

可以用来算识别偏自相关系数.算出来的系数就是偏自相关系数.如果是AR(P),那么从P+1期开始偏自相关系数都是0.偏自相关系数有明显的断尾特征.但是自相关系数是拖尾的,不会断.

### **自回归模型（Autoregressive Model, AR）的定义**

自回归模型（AR模型）是一种时间序列模型，其中当前值由过去若干期的自身值的线性组合表示。自回归模型用于捕捉时间序列数据中的自身相关性。

### **自回归模型的形式**

一个自回归模型AR(p)的形式为：

$$

Y_t = \phi_0 + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \cdots + \phi_p Y_{t-p} + \epsilon_t

$$

其中：

• $Y_t$ 是时间 $t$ 的时间序列值。
• $\phi_0$ 是常数项。
• $\phi_i$ 是自回归系数（i=1, 2, …, p）。
• $Y_{t-i}$ 是时间 $t-i$ 的时间序列值。
• $\epsilon_t$ 是随机误差项，假设其期望为0且方差恒定。

### 自回归模型的平稳条件

  

一阶自回归模型（AR(1)模型）可以表示为：

$$

Y_t = \phi Y_{t-1} + \epsilon_t

$$  

其中：

• $Y_t$ 是时间 $t$ 的时间序列值。
• $\phi$ 是自回归系数。
• $\epsilon_t$ 是白噪声序列，假设其期望为0且方差为恒定（$\sigma^2$）。

我们将证明 $Y_t$ 是白噪声序列 $\epsilon_t$ 的线性组合。

**迭代展开**

首先，我们通过迭代展开$Y_t$的表达式：

  $$

Y_t = \phi Y_{t-1} + \epsilon_t

$$
将$Y_{t-1}$替换为其表达式：
$$

Y_{t-1} = \phi Y_{t-2} + \epsilon_{t-1}

$$
代入$Y_t$中：
$$

Y_t = \phi (\phi Y_{t-2} + \epsilon_{t-1}) + \epsilon_t

$$
简化得到:
$$

Y_t = \phi^2 Y_{t-2} + \phi \epsilon_{t-1} + \epsilon_t

$$
继续迭代：
$$

Y_{t-2} = \phi Y_{t-3} + \epsilon_{t-2}

$$
代入$Y_t$中：
$$

Y_t = \phi^2 (\phi Y_{t-3} + \epsilon_{t-2}) + \phi \epsilon_{t-1} + \epsilon_t

$$
简化得到：
$$

Y_t = \phi^3 Y_{t-3} + \phi^2 \epsilon_{t-2} + \phi \epsilon_{t-1} + \epsilon_t

$$
继续进行下去：
$$

Y_t = \phi^n Y_{t-n} + \sum_{i=0}^{n-1} \phi^i \epsilon_{t-i}

$$
当$n$趋于无穷大时，如果$|\phi| < 1$，则$\phi^n$趋于0。假设时间序列起始于$-\infty$，我们可以忽略$\phi^n Y_{t-n}$项：
$$

Y_t = \sum_{i=0}^{\infty} \phi^i \epsilon_{t-i}

$$
**结论**

上面的推导表明，$Y_t$ 是白噪声序列 $\epsilon_t$ 的线性组合。具体来说，$Y_t$ 是当前及所有过去时期的 $\epsilon_t$ 经过加权后的和，其中权重为 $\phi$ 的幂次。

那么如果要保证自回归模型平稳,$\phi$必须小于1

==一个平稳的AR过程可以转化为一个无穷阶的移动平均过程==

## MA移动平均模型

参数代表自相关系数.MA(q)滞后q+1期的自相关系数统统为0.自相关系数断尾,但是偏自相关系数拖尾. 

### **移动平均模型（Moving Average Model, MA）的定义**

移动平均模型（MA模型）是一种时间序列模型，其中当前时间序列值由当前及过去若干期的误差项的线性组合表示。MA模型用于捕捉时间序列数据中的随机波动特性。

### **MA模型的形式**

一个移动平均模型MA(q)的形式为：

$$

Y_t = \mu + \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}

$$

其中：

• $Y_t$ 是时间 $t$ 的时间序列值。
• $\mu$ 是常数项。
• $\epsilon_t$ 是时间 $t$ 的随机误差项，假设其期望为0且方差为恒定（$\sigma^2$）。
• $\theta_i$ 是移动平均系数（i=1, 2, …, q）。
• $\epsilon_{t-i}$ 是时间 $t-i$ 的误差项。

### **MA模型的可逆性**

MA模型的可逆性（Invertibility）是指模型能够表示成另一种时间序列模型（通常是自回归模型），并且这样的转换是唯一且稳定的。可逆性是MA模型的一个重要特性，因为它确保了模型参数的唯一性和可解释性。

#### MA(1)模型可被转化为无穷阶的自回归模型

我们希望将MA(1)模型转换为无穷阶自回归模型（AR模型），即：

$$

x_t = \sum_{i=1}^{\infty} \phi_i x_{t-i} + u_t

$$

为了实现这个转换，我们需要迭代展开$u_t$的表达式。

**第一步：表达 $u_t$ 和 $u_{t-1}$**
从MA(1)模型出发：

$$

x_t = u_t + \theta_1 u_{t-1}

$$

我们可以解出 $u_t$：

$$

u_t = x_t - \theta_1 u_{t-1}

$$

  接下来，我们将 $u_{t-1}$ 也用 $x$ 和 $u$ 表示：

$$

u_{t-1} = x_{t-1} - \theta_1 u_{t-2}

$$

将 $u_{t-1}$ 代入 $u_t$ 的表达式中：

$$

u_t = x_t - \theta_1 (x_{t-1} - \theta_1 u_{t-2})

$$

简化得到：
$$

u_t = x_t - \theta_1 x_{t-1} + \theta_1^2 u_{t-2}

$$

  **第二步：继续展开 $u_{t-2}$**

类似地，我们可以得到：

$$

u_{t-2} = x_{t-2} - \theta_1 u_{t-3}

$$

将其代入 $u_t$ 的表达式中：

$$

u_t = x_t - \theta_1 x_{t-1} + \theta_1^2 (x_{t-2} - \theta_1 u_{t-3})

$$

简化得到：

$$

u_t = x_t - \theta_1 x_{t-1} + \theta_1^2 x_{t-2} - \theta_1^3 u_{t-3}

$$

**第三步：归纳法证明**

通过继续这一过程，可以得到：

$$

u_t = x_t - \theta_1 x_{t-1} + \theta_1^2 x_{t-2} - \theta_1^3 x_{t-3} + \cdots

$$

将这个表达式代入 $x_t$ 的原始方程中：

$$

x_t = u_t + \theta_1 u_{t-1}

$$

我们用递推法表示 $u_t$，可以得到

$$

x_t = (x_t - \theta_1 x_{t-1} + \theta_1^2 x_{t-2} - \theta_1^3 x_{t-3} + \cdots) + \theta_1 (x_{t-1} - \theta_1 x_{t-2} + \theta_1^2 x_{t-3} - \cdots)

$$

展开并简化得到：

$$

x_t = x_t - \theta_1 x_{t-1} + \theta_1^2 x_{t-2} - \theta_1^3 x_{t-3} + \cdots + \theta_1 x_{t-1} - \theta_1^2 x_{t-2} + \theta_1^3 x_{t-3} - \cdots

$$

所有项相加，我们会发现：

$$
x_t = u_t + \theta_1 u_{t-1} + \theta_1^2 u_{t-2} + \theta_1^3 u_{t-3} + \cdots

$$

我们可以将 $x_t$ 的表达式重新整理为：

$$

x_t = \sum_{i=1}^{\infty} \phi_i x_{t-i} + u_t

$$

其中，$\phi_i = \theta_1^i$。这样，MA(1)模型就被转换成了一个无穷阶的自回归模型。

#### MA模型可逆性条件

由 AR(p)模型平稳性可知， MA(1)模型具有可逆性的条件是$|\theta|$<1。更一般地， 任何一个可逆的MA(q)模型可转换成一个无限阶的自回归模型

##  自回归模型和移动平均模型的关系

偏相关系数被截断了的话,使用AR表示,AR的偏自相关系数是断尾的.
自相关系数被截断的话使用MA表述,MA的自相关系数是断尾的

理解:AR看偏效应,所以偏断自拖,MA相反.

## ARMA自回归移动平均模型

### **ARMA模型的定义**

ARMA模型，即自回归移动平均模型（Autoregressive Moving Average Model），是用于时间序列分析的常见模型。ARMA模型结合了自回归模型（AR）和移动平均模型（MA）的特性，用于捕捉时间序列数据中的动态特征。

自相关系数和偏自相关系数都是拖尾的.

### **ARMA(p, q)模型的形式**

ARMA(p, q)模型可以表示为：

$$

Y_t = \phi_0 + \sum_{i=1}^{p} \phi_i Y_{t-i} + \epsilon_t + \sum_{j=1}^{q} \theta_j \epsilon_{t-j}

$$  
其中：

• $Y_t$ 是时间 $t$ 的时间序列值。
• $\phi_0$ 是常数项。
• $\phi_i$ 是自回归部分的系数（i=1, 2, …, p）。
• $\epsilon_t$ 是时间 $t$ 的随机误差项，假设其期望为0，方差为恒定（$\sigma^2$）。
• $\theta_j$ 是移动平均部分的系数（j=1, 2, …, q）。
• $Y_{t-i}$ 是时间 $t-i$ 的时间序列值。
• $\epsilon_{t-j}$ 是时间 $t-j$ 的误差项。

# VAR向量自回归模型

用一个系统内的所有解释变量的每一期的值来预测后面的每一期解释变量,所有解释变量全部内生,无需也不能有内生性假设,无需先验理论依据.但是只考虑了动态相关,没考虑同期变量的影响.当期的影响会由扰动项来承担.所以扰动项一般都是相关的,非主对角线元素不为0.

## **VAR模型的定义**

VAR模型由多个自回归方程组成，每个方程描述一个时间序列变量与所有变量的滞后值之间的关系。假设我们有 $k$ 个时间序列变量，每个变量在时间 $t$ 的值分别为 $Y_{1,t}, Y_{2,t}, \ldots, Y_{k,t}$，VAR(p)模型可以表示为：

$$ Y_t = \begin{pmatrix} y_{1t} \\ y_{2t} \\\vdots \\ y_{kt} \end{pmatrix} = \sum_{p=1}^{P} \Phi_p Y_{t-p} + \epsilon_t, \quad \epsilon_t \sim (0, \Omega) $$  

其中：

• $Y_t$ 是 $k \times 1$ 的向量，包含所有 $k$ 个时间序列变量在时间 $t$ 的值。
• $A_0$ 是 $k \times 1$ 的向量，包含常数项。
• $A_i$ 是 $k \times k$ 的矩阵，包含滞后期 $i$ 的系数。
• $\epsilon_t$ 是 $k \times 1$ 的向量，包含随机误差项，假设其期望为0，协方差矩阵为 $\Sigma$。
* 滞后阶数由信息准则确定.

## VMA

$$ Y_t = \sum_{s=0}^{\infty} \theta_s \epsilon_{t-s}  $$表示的是当前时间  t  的值  Y_t  可以表示为过去所有时刻的随机误差  \epsilon  的加权和，其中权重是 $\theta_s$。

•	$Y_t$ ：当前时间  t  的值
•	 $\epsilon_{t-s}$ ：过去第  s  时刻的随机误差
•	 $\theta_s$ ：对应于滞后  s  时刻的权重
这意味着当前的  $Y_t$  受到所有过去误差的影响，而这些影响的强度由 $\theta_s$ 决定。

### 权重 $\theta_s$ 的定义

在这些公式中：

•	$\theta_0 = I$，表示当前时间的随机误差对当前值的直接影响。 $I$  是单位矩阵，表示没有滞后的随机误差对当前值的影响完全保留。
•	$\theta_s = \sum_{j=1}^{s} (\Phi_j \theta_{s-j})$，表示滞后  s  时刻的权重 $\theta_s$ 是通过过去的权重 $\theta$ 和自回归系数 $\Phi_j$ 的组合来计算的。

举例:$\theta_{112}$代表2对1间隔1期的影响.顺序完全是倒过来的.间隔1期1受2影响.

## VAR转VMA  

1. VAR(2,1)模型：

$$ \begin{pmatrix} y_{1t} \\ y_{2t} \end{pmatrix} = \begin{pmatrix} \phi_{11} & \phi_{12} \\\phi_{21} & \phi_{22} \end{pmatrix} \begin{pmatrix} y_{1,t-1}\\ y_{2,t-1} \end{pmatrix} + \begin{pmatrix} \epsilon_{1t} \\\epsilon_{2t} \end{pmatrix} $$

2. VMA(2,∞)模型：

$$ \begin{pmatrix} y_{1t} \\ y_{2t} \end{pmatrix} = \begin{pmatrix} \epsilon_{1t} \\\epsilon_{2t} \end{pmatrix} + \begin{pmatrix} \theta_{111} & \theta_{112} \\\theta_{121} & \theta_{122} \end{pmatrix} \begin{pmatrix} \epsilon_{1,t-1} \\\epsilon_{2,t-1} \end{pmatrix} + \begin{pmatrix} \theta_{211} & \theta_{212} \\\theta_{221} & \theta_{222} \end{pmatrix} \begin{pmatrix} \epsilon_{1,t-2} \\\epsilon_{2,t-2} \end{pmatrix} + \cdots $$

## 脉冲响应函数

对于 ( y_2 ) 一个标准差的冲击，( y_1 ) 在当期及未来各期的动态响应函数表示如下：

• 当期（t）：( 0 )
• 下一期（t+1）：( $\vartheta_{112}$)
• 再下一期（t+2）：( $\vartheta_{212}$ )
• 以后各期：( $\vartheta_{312}, \vartheta_{412}, \ldots$ )

积累响应函数表示：

• 当期（t）：( 0 )
• 下一期（t+1）：( $\vartheta_{112}$ )
• 再下一期（t+2）：( $\vartheta_{112} + \vartheta_{212}$ )
• 以后各期：( $\vartheta_{112} + \vartheta_{212} + \vartheta_{312}, \ldots$ )

![[Pasted image 20240620201617.png]]

## 方差分解

$$
\begin{pmatrix}
y_{1t} \\
y_{2t}
\end{pmatrix}

  

\begin{pmatrix}

\epsilon_{1t} \\

\epsilon_{2t}

\end{pmatrix}

+

\begin{pmatrix}

\vartheta_{111} & \vartheta_{112} \\

\vartheta_{121} & \vartheta_{122}

\end{pmatrix}

\begin{pmatrix}

\epsilon_{1,t-1} \\

\epsilon_{2,t-1}

\end{pmatrix}

+

\begin{pmatrix}

\vartheta_{211} & \vartheta_{212} \\

\vartheta_{221} & \vartheta_{222}

\end{pmatrix}

\begin{pmatrix}

\epsilon_{1,t-2} \\

\epsilon_{2,t-2}

\end{pmatrix}

+

\cdots

$$

这里的 $\epsilon_{1t}$ 和 $\epsilon_{2t}$ 是时间 $t$ 的误差项， $\vartheta_{ijk}$ 是冲击响应系数。间隔i期的j受k的影响.

**方差分解公式**

图片中的方差分解公式展示了如何将 $y_{1t}$ 的方差分解为自身和其他变量的贡献：

$$

\text{var}(y_{1t}) = \left(1 + \vartheta_{111}^2 + \vartheta_{211}^2 + \vartheta_{311}^2 + \cdots \right) + \left(\vartheta_{112}^2 + \vartheta_{212}^2 + \vartheta_{312}^2 + \cdots \right)

$$

• 第一部分：$\left(1 + \vartheta_{111}^2 + \vartheta_{211}^2 + \vartheta_{311}^2 + \cdots \right)$ 是 $y_{1}$ 对自身方差的贡献。
• 第二部分：$\left(\vartheta_{112}^2 + \vartheta_{212}^2 + \vartheta_{312}^2 + \cdots \right)$ 是 $y_{2}$ 对 $y_{1}$ 方差的贡献。

## 标准正交化

要将两者重复的信息剔除,进行正交化.将方差协方差矩阵变为对角矩阵.再标准化,得到单位矩阵.

1. **构建VAR模型**：

• 首先，我们构建一个标准的VAR模型：

$$

Y_t = A_1 Y_{t-1} + A_2 Y_{t-2} + \cdots + A_p Y_{t-p} + \epsilon_t

$$

其中，$Y_t$ 是包含多个时间序列变量的向量，$A_i$ 是系数矩阵，$\epsilon_t$ 是误差项向量。

2. **计算误差项的协方差矩阵**：

• 假设误差项的协方差矩阵为 $\Sigma$：

$$

\Sigma = \text{Cov}(\epsilon_t)

$$

由于误差项之间可能存在相关性，因此 $\Sigma$ 通常不是对角矩阵。

3. **Cholesky分解**：

• 使用Cholesky分解将协方差矩阵 $\Sigma$ 分解为下三角矩阵 $P$ 和它的转置 $P’$：

$$

\Sigma = P P’

$$

其中，$P$ 是下三角矩阵。

4. **标准正交化**：

• 通过矩阵 $P$ 对误差项进行标准正交化：

$$

\epsilon_t = P \nu_t

$$

其中，$\nu_t$ 是标准化的误差项，满足 $E(\nu_t \nu_t’) = I$，即 $\nu_t$ 是白噪声。

5. **重新表示VAR模型**：

• 将标准正交化后的误差项代入原VAR模型中，得到正交化后的VAR模型：

$$

Y_t = A_1 Y_{t-1} + A_2 Y_{t-2} + \cdots + A_p Y_{t-p} + P \nu_t

$$

其中，$\nu_t$ 是正交化后的冲击向量。

这之后再进行方差分解就可以得到加起来刚好是总的.但是还是不对,谁先来,谁把公共部分就占了.

先观测的大.

## 格兰杰因果关系检验

**VAR模型的设定**

假设我们有两个时间序列变量 $y_{1t}$ 和 $y_{2t}$，它们的VAR(p)模型可以表示为：

$$

\begin{pmatrix}

y_{1t} \\

y_{2t}

\end{pmatrix}

  =


\sum_{i=1}^{p}

\begin{pmatrix}

\phi_{i11} & \phi_{i12} \\

\phi_{i21} & \phi_{i22}

\end{pmatrix}

\begin{pmatrix}

y_{1,t-i} \\

y_{2,t-i}

\end{pmatrix}

+

\begin{pmatrix}

\epsilon_{1t} \\

\epsilon_{2t}

\end{pmatrix}

$$

  

其中，$\epsilon_{1t}$ 和 $\epsilon_{2t}$ 是误差项。

**格兰杰因果关系检验的步骤**

1. **构建回归模型**：

• 对每个变量构建包含所有滞后项的回归模型。

2. **原假设和备择假设**：

• 原假设 $H_0$：$y_{2t}$ 不是 $y_{1t}$ 的格兰杰原因，即 $\phi_{i12} = 0$ 对所有 $i$ 都成立。
• 备择假设 $H_1$：$y_{2t}$ 是 $y_{1t}$ 的格兰杰原因，即至少有一个 $\phi_{12,i} \neq 0$。

3. **计算F统计量**：

• 通过比较包含和不包含 $y_{2}$ 滞后项的模型的残差平方和来计算F统计量。

4. **判定**：

• 根据F统计量和相应的临界值，判断是否拒绝原假设。如果拒绝原假设，则认为 $y_{2t}$ 是 $y_{1t}$ 的格兰杰原因。

实际上是检验动态的相关性,其实不是因果.