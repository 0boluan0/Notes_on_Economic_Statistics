
# 数据平稳性

## 协方差平稳

期望和方差是有限常数,协方差只和时间间隔有关,不随时间变化.

## 随机趋势:单位跟过程

**公式推导**

1. **随机过程的定义**：
$$ y_t = y_{t-1} + \epsilon_t $$

其中，$\epsilon_t \sim iid(0, \sigma^2)$，表示误差项是均值为0、方差为$\sigma^2$的独立同分布随机变量。

2. **展开表达式**：
通过递归展开$y_t$，我们得到：
$$ y_t = y_{t-1} + \epsilon_t $$
$$ y_{t-1} = y_{t-2} + \epsilon_{t-1} $$

代入上式，得到：
$$ y_t = y_{t-2} + \epsilon_{t-1} + \epsilon_t $$
继续递归展开，得到：
$$ y_t = y_0 + \sum_{i=1}^t \epsilon_i $$
3. **总结表达式**：
因此，$y_t$可以表示为所有过去误差项的累积和：

$$ y_t = \sum_{i=0}^t \epsilon_i $$
相当于积分,一阶求积过程,即$Y_t$~$I(1)$

即序列收到冲击不衰减.永久记忆.

## 高阶求积过程

就是将上面搞过的再来一遍,.形成二阶求积过程,两个单位根.

## 平稳过程

### 零值回复

零值回复过程指的是时间序列数据在短期内可能偏离其均值，但在长期内会回到其均值。即，它的均值、方差和自相关结构不随时间变化。

  

**公式**：

$$ y_t = \rho y_{t-1}  + \epsilon_t $$

其中：

* $\rho$是介于-1和1之间的系数
* $\epsilon_t$ 是均值为0、方差为 $\sigma^2$ 的白噪声项/

向0回复

### 漂移

$$ y_t = \alpha+\rho y_{t-1}  + \epsilon_t $$

向$\alpha$回复

### 漂移和时间趋势

$$ y_t = \alpha+\beta t+\rho y_{t-1}  + \epsilon_t $$

向$\alpha + \beta t$回复

## 平稳的本质

* 序列所受到的冲击会逐渐减弱,不存在永久记忆.
* 数据序列存在向某一确定性路径回复的内在趋势,即数据存在自稳定机制.

# 单位根检验和平稳性检验

## 单位根检验-DF检验

  

Dickey-Fuller检验（DF检验）是用于检验时间序列是否具有单位根的一种统计方法。单位根的存在意味着时间序列是非平稳的，而平稳性是许多时间序列分析方法的前提条件。

  

### **1. DF检验的基本形式**

Dickey-Fuller检验的基本形式是检验以下模型中的 $\rho$ 是否等于1：

$$

y_t = \rho y_{t-1} + \epsilon_t

$$  
通过对两边进行差分变换，得到：

$$

\Delta y_t = \gamma y_{t-1} + \epsilon_t

$$

其中，$\Delta y_t = y_t - y_{t-1}$，$\gamma = \rho - 1$。因此，检验 $\rho = 1$ 等价于检验 $\gamma = 0$。

### 2. **原假设和备择假设**

• **原假设（$H_0$）**：$r = 0$，表示时间序列存在单位根，是非平稳的。
• **备择假设（$H_1$）**：$r < 0$，表示时间序列不存在单位根，是平稳的。

### **3. 统计量**

检验统计量 $\tau$ 为：
$$

\tau = \frac{\hat{r}}{se(\hat{r})}

$$

其中，$\hat{r}$ 是 $r$ 的估计值，$se(\hat{r})$ 是 $\hat{r}$ 的标准误。  

### **4. 分布和临界值**

• 统计量 $\tau$ 的分布是左偏不对称的。
• 使用模拟方法获得不同情况下的临界值。
• 根据图片内容，在样本量 $T = 500$，模拟次数 $N = 1000$ 的情况下，给出了不同显著性水平下的临界值：
• 显著性水平 $\alpha = 0.05$ 对应的临界值 $t_\alpha = -1.64369$
• DF检验的临界值分别为：
• $DF1_\alpha = -1.94576$（无常数项和趋势项）
• $DF2_\alpha = -2.76722$（有常数项，无趋势项）
• $DF3_\alpha = -3.10853$（有常数项和趋势项）
![[Pasted image 20240621170721.png]]

红线是零值回复,蓝线是漂移,棕线是漂移和时间趋势

Dickey-Fuller检验的统计量用于检验时间序列是否具有单位根。虽然我们计算的DF检验统计量形式上类似于t统计量，但其实际分布不同，具体来说，DF检验统计量服从$\tau$分布而非t分布。这是因为时间序列的单位根性质会导致其误差项的累积效应，从而影响统计量的分布。


###  **数学证明**

为了说明DF检验统计量为什么服从$\tau$分布，我们从以下几个方面进行解释：


#### **1. DF检验模型**

考虑DF检验的基本模型：

$$

\Delta y_t = \gamma y_{t-1} + \epsilon_t

$$

其中，$\Delta y_t = y_t - y_{t-1}$，$\gamma = \rho - 1$，$\epsilon_t$是白噪声。

#### **2. 单位根下的时间序列特性**

在单位根假设下，即$\rho = 1$，则$\gamma = 0$，时间序列$y_t$可以表示为：

$$

y_t = y_{t-1} + \epsilon_t

$$

通过迭代，得到：  

$$

y_t = y_0 + \sum_{i=1}^t \epsilon_i

$$

这表明，$y_t$是误差项$\epsilon_t$的累积和。

#### **3. 统计量形式**

在DF检验中，我们需要检验$\gamma = 0$，即检验：

$$

\hat{\gamma} = \frac{\sum_{t=2}^T y_{t-1} \Delta y_t}{\sum_{t=2}^T y_{t-1}^2}

$$

通过计算标准误，得到检验统计量：

$$

\tau = \frac{\hat{\gamma}}{se(\hat{\gamma})}

$$

#### **4. 统计量的分布**

为了理解$\tau$统计量的分布，我们考虑在单位根假设下$y_t$的行为：

$$

\hat{\gamma} = \frac{\sum_{t=2}^T y_{t-1} \Delta y_t}{\sum_{t=2}^T y_{t-1}^2} = \frac{\sum_{t=2}^T y_{t-1} (y_t - y_{t-1})}{\sum_{t=2}^T y_{t-1}^2} = \frac{\sum_{t=2}^T y_{t-1} \epsilon_t}{\sum_{t=2}^T y_{t-1}^2}

$$  

由于$y_t$是单位根过程，所以$y_{t-1}$是误差项$\epsilon_t$的累积和：

$$

y_{t-1} = y_0 + \sum_{i=1}^{t-1} \epsilon_i

$$


因此，$\sum_{t=2}^T y_{t-1} \epsilon_t$的分布将受到累积误差项的影响，而不仅仅是独立同分布的误差项的影响。

![[Pasted image 20240621195025.png]]

#### **5. $\tau$分布与t分布的差异**

t分布假设样本中的观察值是独立同分布的，而在单位根时间序列中，$y_t$的观察值是高度相关的。具体来说，$y_t$的当前值不仅依赖于当前的误差项，还依赖于所有过去的误差项。

这种累积效应导致了检验统计量$\tau$的分布与t分布不同。t分布是对独立同分布变量的适当描述，而$\tau$分布则反映了时间序列中的相关性和累积误差项的影响。

**直观解释**  

• t分布：适用于独立同分布的样本。
• $\tau$分布：适用于具有单位根的时间序列样本，因为这些样本中的观察值是高度相关的，且误差项的累积效应影响了统计量的分布。

## ADF检验

### 1.ADF检验内容

相较于DF检验,ADF加入了滞后项,因为DF检验认为误差项是白噪声过程,而事实上大概率不是.加入滞后项可以消除误差项之间的影响.具体滞后的阶数使用信息准则来约束.其他的与DF检验一致

1. **无常数项和趋势项**：
$$
\Delta y_t = \gamma y_{t-1} + \sum_{i=1}^{k} \alpha_i \Delta y_{t-i} + \epsilon_t
$$

2. **有常数项，无趋势项**：
$$
\Delta y_t = \alpha + \gamma y_{t-1} + \sum_{i=1}^{k} \alpha_i \Delta y_{t-i} + \epsilon_t
$$

3. **有常数项和趋势项**：
$$
\Delta y_t = \alpha + \beta t + \gamma y_{t-1} + \sum_{i=1}^{k} \alpha_i \Delta y_{t-i} + \epsilon_t
$$

### **2. 为什么需要ADF检验？**

**自相关问题**

在时间序列数据中，误差项 $\epsilon_t$ 可能存在自相关，即误差项之间可能不是独立的。基本的DF检验假设误差项是白噪声（即独立同分布），但在实际数据中，这一假设经常被违反。  

• **自相关的影响**：如果误差项存在自相关，那么基本的DF检验模型可能会低估$\gamma$的标准误，从而影响检验的有效性，可能导致单位根的错误判定。

**解决自相关问题**

为了消除误差项之间的自相关，ADF检验在回归模型中引入了滞后项 $\Delta y_{t-i}$。这些滞后项有助于捕捉和调整数据中的自相关结构，从而提高检验结果的可靠性。

### **3. ADF检验的具体步骤**


**步骤1：选择滞后阶数**

选择合适的滞后阶数 $k$，可以使用信息准则（如AIC、BIC）来确定最优的滞后阶数。

**步骤2：构建模型**

根据选择的ADF检验形式，构建相应的回归模型。

**步骤3：估计参数**

通过最小二乘法（OLS）估计模型参数。

**步骤4：计算检验统计量**

计算 $\gamma$ 的t统计量，并与临界值比较。

**步骤5：判定**  

根据t统计量与临界值比较，判断是否拒绝原假设（$H_0: \gamma = 0$）。若拒绝原假设，则认为时间序列没有单位根，是平稳的。

### 4.如果非要用DF,后果是:

 ![[Pasted image 20240621193942.png]]

## PP检验

PP检验（Phillips-Perron检验）是用于检验时间序列数据是否具有单位根的另一种方法。与ADF检验（Augmented Dickey-Fuller检验）相似，PP检验也是检验时间序列平稳性的重要工具。PP检验通过直接调整DF检验统计量的自相关和异方差问题，从而改进单位根检验的效果。

### **1. PP检验的基本思想**  

与ADF检验相比，PP检验的主要区别在于其处理序列相关性和异方差的方法。ADF检验通过引入滞后项来解决自相关问题，而PP检验通过修改DF检验统计量的标准误来调整自相关和异方差。

### **2. PP检验模型**

PP检验的基本模型与DF检验相同：

1. **无常数项和趋势项**：
$$
\Delta y_t = \gamma y_{t-1} + \epsilon_t
$$

2. **有常数项，无趋势项**：
$$
\Delta y_t = \alpha + \gamma y_{t-1} + \epsilon_t
$$

3. **有常数项和趋势项**：
$$
\Delta y_t = \alpha + \beta t + \gamma y_{t-1} + \epsilon_t
$$

### **3. PP检验的步骤**

**步骤1：估计基本回归模型**

与DF检验一样，首先估计基本的回归模型，并计算残差项$\hat{\epsilon_t}$。

**步骤2：计算DF检验统计量**

计算$\gamma$的t统计量（即DF检验统计量）：

$$

t_{\gamma} = \frac{\hat{\gamma}}{se(\hat{\gamma})}

$$

**步骤3：调整标准误**

PP检验通过调整DF检验统计量的标准误来处理自相关和异方差问题。调整后的标准误为：

$$

se(\hat{\gamma}) = \sqrt{\frac{\hat{\sigma}^2}{\sum_{t=1}^{T} y_{t-1}^2}}

$$

其中，$\hat{\sigma}^2$是残差的长滞后方差估计，可以通过Newey-West方法计算。

**步骤4：计算调整后的检验统计量**

调整后的PP检验统计量为：

$$

Z_{\gamma} = t_{\gamma} - \frac{T \cdot \hat{\sigma}_{\epsilon}^2}{2 \sum_{t=1}^{T} y_{t-1}^2}

$$

### **4. PP检验与ADF检验的差别**  

• **处理自相关和异方差的方法**：

• ADF检验：通过引入滞后项解决自相关问题。
• PP检验：通过直接调整DF检验统计量的标准误解决自相关和异方差问题。

• **模型复杂度**：

• ADF检验：模型中引入了多个滞后项，模型较为复杂。
• PP检验：不引入滞后项，直接调整标准误，模型相对简单。

• **适用性**：

• ADF检验：适用于大多数时间序列，但需要选择合适的滞后阶数。
• PP检验：不需要选择滞后阶数，更适合处理异方差问题严重的时间序列。

# 协积(协整)和误差纠正机制

协整关系是指多个非平稳时间序列的线性组合结果是平稳的，这表明这些时间序列之间存在长期的均衡关系。即使这些时间序列本身是非平稳的，但它们在某种线性组合下可能会呈现出平稳性  

## **例子说明**

我们有两个随机游走过程：

$$

y_t = y_{t-1} + u_t, \quad u_t \sim iid , N(0,1)

$$

$$

x_t = x_{t-1} + v_t, \quad v_t \sim iid , N(0,1)

$$

### **解释**

1. **随机游走**：两个变量$y_t$和$x_t$都是随机游走过程，即它们是非平稳的，因为它们的方差随着时间增加而增加。
2. **误差项**：$u_t$和$v_t$是均值为0、方差为1的独立同分布正态随机变量。

### **协整关系的描述**

即使$y_t$和$x_t$本身是非平稳的，但它们可能存在某种线性组合，使得该组合是平稳的。例如，假设存在一个常数$\beta$使得：

$$

\epsilon_t = y_t - \beta x_t

$$

如果$\epsilon_t$是平稳的，即$\epsilon_t \sim I(0)$，那么我们说$y_t$和$x_t$是协整的，协整系数为$\beta$。

### **检验协整关系**

为了确定$y_t$和$x_t$是否协整，可以进行以下步骤：

**步骤1：估计协整系数$\beta$**

通过回归分析，可以估计协整系数$\beta$：

$$

y_t = \alpha + \beta x_t + \epsilon_t

$$

其中，$\alpha$是常数项，$\epsilon_t$是残差。

**步骤2：检验残差的平稳性**

检验残差$\epsilon_t$是否平稳。如果$\epsilon_t$是平稳的，那么$y_t$和$x_t$之间存在协整关系。

可以使用ADF检验或PP检验来检验残差的平稳性。

## 伪回归

伪回归指的是在时间序列分析中，当两个或多个非平稳时间序列进行回归分析时，尽管这些序列之间没有实际的关系，但回归结果却显示出高度显著的统计关系。这种现象通常是由于时间序列中的趋势或随机游走成分所导致的，并不代表真正的经济关系。

任意两个I（几）过程的时间序列都能回归出来一个显著的值，所以之前的方法就不适用了，就得用新的方法

### **示例描述**

1. **独立的随机游走序列**：

• $y_t$ 和 $x_t$ 是完全独立的随机游走序列。
• 数据生成过程（DGP）为：

$$

y_t = y_{t-1} + u_t, \quad u_t \sim iid , N(0,1)

$$
$$

x_t = x_{t-1} + v_t, \quad v_t \sim iid , N(0,1)

$$

• 这表示$y_t$和$x_t$都是单位根过程（随机游走），它们的当前值是前期值加上一个随机误差项。

2. **样本量和模拟次数**：

• 样本量 $T = 100$，即每个时间序列包含100个观测值。s
• 模拟次数 $N = 100$，即进行100次模拟实验。

3. **回归模型**：

• 使用线性回归模型：
$$

y_t = \beta_0 + \beta_1 x_t + \epsilon_t

$$

• 尽管$y_t$和$x_t$实际上是无关的，我们进行回归分析以检验它们之间的关系。

4. **显著性检验结果**：

• 在0.05显著性水平下，75次拒绝原假设（即$75%$的模拟实验中，回归结果显示$\beta_1$显著）。

• 这意味着尽管$y_t$和$x_t$实际上没有关系，回归分析结果却显示出75次中有显著的关系，显示出伪回归现象。

## 协整

现在看两个I(1)过程是否有关系,需要看二者是否协整.

**1. 协整关系**

• **非平稳时间序列**：$y \sim I(1)$ 和 $x \sim I(1)$ 表示 $y$ 和 $x$ 是两个一阶单整（非平稳）的时间序列。
• **线性回归模型**：$y = x \beta + \epsilon$，其中 $\epsilon$ 是残差项。如果 $y$ 和 $x$ 之间存在协整关系，则残差 $\epsilon \sim I(0)$ 是平稳的。

**2. 协整**

• **残差平稳**：如果 $y$ 和 $x$ 协整，则残差 $\epsilon_t$ 是平稳的，即 $\epsilon \sim I(0)$。
• **误差纠正模型**：对残差 $\epsilon_t$ 的差分 $\Delta \epsilon_t$ 进行建模：

$$

\Delta \epsilon_t = r \epsilon_{t-1} + u_t

$$
其中，如果y和x协整,那么$r < 0$，表示残差有回归到均值的趋势，$u_t$ 是白噪声误差项。

### 误差纠正机制ECM

误差纠正模型（Error Correction Model, ECM）用于描述协整时间序列之间的动态调整过程。

• **差分方程**：协整关系可以表示为差分方程：

$$

\Delta y = \Delta x \beta + \Delta \epsilon = \Delta x \beta + r \epsilon_{t-1} + u_t

$$

• **前一期误差项**：误差项 $\epsilon_{t-1}$ 表示前一期的协整误差，即：

$$

\epsilon_{t-1} = y_{t-1} - x_{t-1} \beta

$$

这个项表示$y_{t-1}$ 和 $x_{t-1}$ 之间的偏离。

  代表上一期偏离均衡值的差值会在这一期以$\gamma$的比率被修正.

# 基于残差的协整检验

基本思想是先估计出来y和x的一元线性回归,然后看残差项是不是平稳的.因为有两步所以名字叫做:

## EG两步检验法

实际上是对残差做单位根检验,也就是对y和x的线性组合做单位根检验.

在对残差做单位根检验的时候出了问题.临界值不能用原来的那张表,需要用麦金农算出来的表,因为残差不可观测,原来那个就不能用了.其他的一概不变.

只能识别整体的协整关系.

# 基于误差纠正机制的协积检验

### **Johansen检验的基本思想**

Johansen检验基于以下模型：

$$

\Delta y_t = \Pi y_{t-1} + \sum_{i=1}^{k-1} \Gamma_i \Delta y_{t-i} + \epsilon_t

$$

其中：

• $y_t$ 是包含多个变量的向量。
• $\Delta y_t$ 是 $y_t$ 的差分。
• $\Pi$ 和 $\Gamma_i$ 是系数矩阵。
• $\epsilon_t$ 是误差项。

Johansen检验主要关注矩阵 $\Pi$，该矩阵的秩（rank）决定了协整关系的数量。

### **Johansen检验的步骤**

**步骤1：确定VAR模型的滞后阶数**

使用信息准则（如AIC、BIC）确定VAR模型的滞后阶数 $k$。

**步骤2：构建VAR模型并估计参数**

根据确定的滞后阶数 $k$ 构建VAR模型，并估计参数。

**步骤3：计算协整矩阵 $\Pi$**

通过最大似然估计方法计算协整矩阵 $\Pi$。

**步骤4：检验协整关系**

使用Johansen检验统计量检验协整关系，主要有两种统计量：

• Trace检验统计量
• 最大特征值检验统计量

### **Johansen检验统计量**

**1. Trace检验统计量**

Trace检验统计量用于检验至少存在 $r$ 个协整关系的原假设。

$$

\text{Trace Statistic} = -T \sum_{i=r+1}^{p} \ln(1 - \lambda_i)

$$

其中，$T$ 是样本量，$\lambda_i$ 是协整矩阵 $\Pi$ 的特征值。原假设r个协整方程,备择假设k个协整方程.

**2. 最大特征值检验统计量**

最大特征值检验统计量用于检验恰好存在 $r$ 个协整关系的原假设。  

$$

\text{Max-Eigen Statistic} = -T \ln(1 - \lambda_{r+1})

$$

两个都是从0往上加,看到哪里第一次不拒绝,就最多有几个.

