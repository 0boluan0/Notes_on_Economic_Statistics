# 回归：从身高问题的分析讲起、
## 起源

> 回归：regression
* 源自生物统计中的概念。最初被用于描述子代与父代的身高关系，子代身高与父代身高有较强的关联。
* ![[Pasted image 20240228202716.png]]
* 每一组的均值都是条件均值。即：在父代的身高确定的情况下，子代身高样本的均值。表示为![[Pasted image 20240228131447.png]]
* y的实际水平会随着其他的一系列的不可控的随机因素的干扰，故给原式中加入一个随机扰动（误差），以符合现实情况。

## 意义
**y的取值最终会向由解释变量x所决定的平均水平上回复，这种回复的趋势叫做回归（regression）。**
>注意：一定是y向x回归。且不是向x的值回归，而是向着x决定的那个均值回归。

---

# 一元线性回归（书上第三章）

## 总体回归方程

![[Pasted image 20240228132651.png]]


 **反应最真实的数量关系**，是真实存在的对象，是研究者想要研究的，但是事实上无法真实全知的值。
 * 总体回归方程将我们要研究的数据分成了两个部分，一个是前边两个部分，这部分我们可以理解并解释，而后面的扰动项我们无法解释
 * 方程的来源：前沿的研究与朴素的共性认知。 

N是样本容量，根据容量不同分为[[零散知识点#大样本与小样本|大样本和小样本]]。

![[Pasted image 20240305082342.png]]
条件期望（不是均值，总体只有期望没有均值，反之样本只有均值没有期望）

### 推导：如何从[[Pasted image 20240228132651.png|总体回归方程]]推导到[[Pasted image 20240305082342.png|总体期望方程]]

对总体回归方程左右同取期望，u的期望是0，得到了总体的期望方程

### 为什么u的期望一定是0

深层原因是因为贝塔0的存在，任何不为0的值都可以归到贝塔0中去。

## 样本回归方程

![[Pasted image 20240304203122.png]]
其中的贝塔0hat和贝塔1hat依靠[[零散知识点#残差|残差]]决定。
已知![[Pasted image 20240305130551.png]]
那么残差的值就是取Y和Yhat这两个列向量的[[零散知识点#欧几里得距离|欧几里得距离]]，即取残差平方和。

---

# 最小二乘法ordinary least square

二乘就是平方的意思，引进的时候翻译不到位。

## 推导

由上面的过程得知，现在要求残差平方和最小，即![[Pasted image 20240305131708.png]]

要求其极小值，只需要一阶偏导得零即可，不需要二阶偏导为正，因为现在要求的是残差平方和极小值，而残差平方和不存在极大值，故其一阶偏导为0时就一定是极小值点。

**由此推知一阶优化条件**：
![[Pasted image 20240305132555.png]]

由一阶优化条件得到正规方程组
## 正规方程组：

![[Pasted image 20240305133741.png]]

>如何理解正规方程组的意义？

事实啥高是对贝塔0hat和贝塔1hat做偏导得到的

### 意义

![[Pasted image 20240306174249.png]]
是对贝塔0hat求偏导得到的，意味着残差的均值为0

![[Pasted image 20240306174325.png]]

是对贝塔1hat求偏导得到的，意味着x和uhat的样本协方差为0，因为这个除以自由度就是样本协方差的公式，这个式子相当于是分子.即说明**xi和ui正交**
所以这两个公式是由第一个推导得到第二个。

### 思考：为什么不用协方差

协方差受量纲影响，所以不是很好。

### 思考：为什么不取绝对值

绝对值函数不连续，取绝对值后没法求导。

### 辨析：欧几里得距离和曼哈顿距离

* [[零散知识点#欧几里得距离|欧几里得距离]]是用两点与坐标系构成的直角三角形的斜边的距离来描述两点的距离
* 曼哈顿距离是用两点与坐标系构成的支教三角形的两直角边的距离相加来描述两点的距离


## 贝塔0hat和贝塔1hat的解法

![[Pasted image 20240310184421.png]]
贝塔1hat有意义且重要，相比之下贝塔0hat没有严格的意义但还是必须得有，没有则正规方程组不成立
在对应具体样本时，贝塔0hat和贝塔1hat是[[零散知识点#估计量 estimator|估计量]]（最小二乘估计量）
但是在不对应具体样本时，二者为[[零散知识点#统计量|统计量]]

---

# 高斯-马尔可夫定理
## 基本假定（经典假定）

### 1. 线性
回归方程对参数（系数）线性
下面这些都算线性
![[Pasted image 20240310184955.png]]
### 2.解释变量x严格外生
 ![[Pasted image 20240310185423.png]]
注意此处并没有下表的限制，意味着任意的x和任意的u都不相关，即u不受过去现在将来的任何x的影响，即不可被观测，这显然是一种极其苛刻的要求，事实上是不存在这样的情况的。
### 3. 误差项零均值、同方差、无自相关
![[Pasted image 20240310185642.png]]
u零均值就是正则表达式的第一条的情况
同方差就好比俩人去量同一个桌子的高度，两个人的细心程度是一样的，这就意味着我在算桌子的真实高度时就可以进行简单的加算，而最小二乘法用的就是加算，所以必须满足这个要求
无自相关就好比去分别找两个人借100块钱，两人都答应了，但是你不知道这俩人是一家的，事实上有50块是共有的，最后会对你能借到的钱产生影响。

---

## 高斯-马尔可夫定理内容
![[Pasted image 20240310190106.png]]
最小方差线性无偏估计(Best Linear Unbiased Estimator)
### 1. 线性

![[Pasted image 20240310190123.png]]
换句话说就是y是b的线性组合
正态分布的线性组合还是正态分布假定扰动项正态分布，那么y也会是正态分布，构造已知分布的统计量，命题都是对参数的约束

### 2. 无偏性（有限样本）一致性（大样本）
我们事实上是在用贝塔hat估计贝塔，就像打靶一样，无偏意味着我的弹孔围绕着那个靶心，虽然环数不同，但是最后算出的平均的中心点肯定跟靶子的十环重合。贝塔hat减去贝塔就做误差，而贝塔hat的期望和贝塔的差值叫偏误。
严格外生则无偏，如果x和u正相关，则贝塔hat会被系统性高估。
推导过程见备忘录
严格外生很好，但是极难实现
对于大样本来讲，只需要实现弱外生就行（x和自己对应的u无关就行），这种情况叫做一致性。![[Pasted image 20240313092346.png]]

### 3. 最优性
误差项零均值：前面写过了
同方差：因为OLS直接加总没有赋权，所以在异方差情况下总的方差一定增大，故而要求同方差。
无自相关：保证信息的独立。

---

## 拟合优度

### 思想
![[Pasted image 20240313092834.png]]
这是对于模型的评价。
y的变化由x的影响与u的影响两部分组成，我们是想让x的部分尽可能大，u的部分尽可能小。

### 推导

1. 方差分解
	即将总的波动划分为解释变量的影响与随机冲击的影响
	![[Pasted image 20240313154426.png]]
	其中，最后一项实际上是没有除自由度的样本协方差
2. 由y与u正交可知，最后一项的数值为0
	![[Pasted image 20240313154546.png]]
3. 此时我们达成了第一步的目的，将总波动划分为了两个部分。
	![[Pasted image 20240313154633.png]]，随机冲击的部分，RSS
	![[Pasted image 20240313154727.png]]，总的部分，TSS
	![[Pasted image 20240313154743.png]]，解释变量的影响部分，ESS，解释平方和。
4. 用![[Pasted image 20240313154820.png]]，来表示解释变量的变化对于总的变化的影响程度，通常来讲是越高越好。

---

## 参数的约束检验  

### 参数推导
假设u的分布为正态分布，进行参数约束检验，检验参数是否满足某个约束。

1. ![[Pasted image 20240316104718.png]]
	假定u服从正态分布，且已知u的均值是0
2. 那么y的分布也是正态分布，贝塔hat也是正态分布，对贝塔hat进行标准化。![[Pasted image 20240316105017.png]]
	但是这个Z不能用，因为sd（贝塔hat）里用到了西格玛方，是总体参数，不知道它的具体值是什么，所以不能用。
3. 估计![[Pasted image 20240316105441.png]]，![[Pasted image 20240316105449.png]]是总体的方差，用氧泵的方差来估计![[Pasted image 20240316105511.png]]
 ![[Pasted image 20240316110607.png]]![[Pasted image 20240316110709.png]] ![[Pasted image 20240316110732.png]]
4. ![[Pasted image 20240316110227.png]]
5. ![[Pasted image 20240316111302.png]]
6. 得到了标准误，相当于![[Pasted image 20240316111345.png]]的方差。用标准误代替标准差得出t统计量：![[Pasted image 20240316111444.png]]
![[Pasted image 20240316111643.png]]

### 参数检验

#### t检验
![[Pasted image 20240316111724.png]]
一般我们更喜欢使用单侧检验，把想要确认的结论放在H1而不是H0，因为[[零散知识点#第一类错误与第二类错误|第二类错误]]的出错概率不可知。在假设时应该确保H0里面有等号。
* a叫做显著性水平，衡量两种错误的可接受程度来选择a。
![[Pasted image 20240316113034.png]]
#### p值

![[Pasted image 20240316112531.png]]
实际效果不变，但是使用P值而非简单的a可以报告出更多的经济信息
## eg：中国的消费函数

![[Pasted image 20240316113415.png]]

最上面的一行是贝塔hat![[Pasted image 20240316113446.png]]
中间的一行是标准误![[Pasted image 20240316113524.png]]
最先面一行是T-ratio(T比率），看的是跟0的距离。![[Pasted image 20240316120634.png]]

![[Pasted image 20240316121914.png]]拟合优度。

---

## 区间估计
![[Pasted image 20240316121557.png]]
既可以是对个体的预测，也可以是对均值的预测。
二者仅相差u。所以对均值的预测更为准确

---

## MC仿真

蒙特卡洛仿真是一种基于随机抽样的数值计算方法，用于解决各种数学、物理和工程问题，尤其是当问题难以通过解析方法求解时。该方法以蒙特卡洛赌场为名，因为它利用了随机抽样的思想，类似于在赌场中使用随机性来估计结果。

蒙特卡洛仿真的基本思想是通过生成大量的随机样本来近似地估计一个问题的解或性质。它的流程通常包括以下步骤：

1. **定义问题**：明确定义要解决的问题，包括问题的输入、输出和所需的解或性质。

2. **建立模型**：将问题建模为一个数学模型，包括定义随机变量和其分布，以及确定求解的目标。

3. **生成随机样本**：使用随机抽样方法，如均匀分布、正态分布等，在输入空间中生成大量的随机样本。

4. **计算估计值**：将随机样本代入模型中，计算得到问题的解或性质的近似值。

5. **分析结果**：对估计值进行统计分析，包括计算估计的误差范围和置信区间等。

6. **调整参数**：根据需要，调整随机抽样的参数或增加样本量，以提高估计的准确性。

蒙特卡洛仿真在金融领域、物理学、工程学、生物学等领域都有广泛的应用，特别是在涉及高维、复杂的问题或无法求解的问题上。

![[Pasted image 20240316134412.png]]
事实证明OLS是所有一元线性回归方法中最优的那一个。
