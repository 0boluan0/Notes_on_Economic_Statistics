
四个部分

ARMA

ARCH,GARCH

VAR

Nonstationary time series

# 1.概率论复习

## 1.1 概率空间

一个概率空间是一个三元组 $(S, \mathbb{B}, P)$，其中：

- $S$ 是样本空间（sample space），对应于基础随机实验的所有可能结果。
- $\mathbb{B}$ 是 $S$ 的 **$\sigma$-代数**（$\sigma$-field），即 $S$ 的子集的集合，这些子集称为**事件**（events）。
- $P: \mathbb{B} \to [0,1]$ 是**概率测度**（probability measure），用于分配事件的概率。

>[!example] 示例：抛硬币（Coin Throwing）
>假设：
>- $S = \{-1,1\}$，表示两种可能的结果（例如 $-1$ 代表正面，$1$ 代表反面）。
>- $\mathbb{B} = \{\emptyset, S, \{1\}, \{-1\} \}$，表示事件集合，包括空集、全集以及单个事件 $\{1\}$ 和 $\{-1\}$。
>- 概率分布如下：
  $$ P(x = -1) = P(x = 1) = \frac{1}{2} $$
  这描述了一个**公平抛硬币**的概率空间，其中 $x = -1$ 和 $x = 1$ 发生的概率相等，均为 $\frac{1}{2}$。

* 拓展:

Martingale pricing
Black ——Scholes
girsanov theorem
想学的自己搜吧

## 1.2  **Probability densities and distributions (pmf/pdf, CDF)**

离散与连续型随机变量。随机变量 $X$ 的累积分布函数 (CDF) 定义为：

$$
F_{X}(x) = P\bigl(X \le x\bigr) \quad \forall  x \in \mathbb{R}.
$$

## 1.3 **Expectation and population moments**

假设 $X$ 是一个具有概率质量函数或概率密度函数  $f_X(x)$的随机变量。则可测函数$g(x)$的期望定义为：
$$
E(g(X)) = \int_{-\infty}^{\infty} g(x)dF_X(x).
$$
当$g(X) = X$时，这是第一矩（均值）。

## 1.4联合分布与独立性

随机变量 $X$ 和 $Y$ 的联合 CDF 定义如下：

$$
F_{X,Y}(x,y) = P(X \le x, \, Y \le y) = P(X \le x \cap Y \le y),
$$

对于任意 $(x,y) \in \mathbb{R}^2$。当且仅当

$$
F_{X,Y}(x,y) = F_X(x)\,F_Y(y),
$$

对所有 $(x,y) \in \mathbb{R}^2$ 都成立时，$X$ 和 $Y$ 独立。

## 1.5迭代期望定理

>[!note] 迭代期望定义
>在一个概率空间中，若有两个子-$\sigma$-代数 $\mathcal{G}_1 \subseteq \mathcal{G}_2 \subseteq \mathcal{B}$，并且给定一个随机变量 $X$，则有
>$$
>E\bigl[E[X \mid \mathcal{G}_2] \mid \mathcal{G}_1\bigr] = E[X \mid \mathcal{G}_1].
>$$

>[!example] 示例
>==较小的子-$\sigma$-代数主导==
>直觉：较小的子 $\sigma$-代数起支配作用！
>* 示例 1
>考虑回归模型$Y = X\beta + \varepsilon$。假设$E(\varepsilon \mid X) = 0$比$E(\varepsilon) = 0$或$E(X\varepsilon) = 0$更强，因为前者蕴含后者。
>* 示例 2
>在宏观经济学或金融学中，对于跨期世代模型（OLG），我们通常使用性质$E_t(X) = E_{t+1}(X)$，其中 $E_t$ 表示在时间 $t$ 之前的信息（$\sigma$-代数）条件下的期望。

- **子 $\sigma$-代数**可以理解为“包含的信息量”不同的视角：  
  若有两个子 $\sigma$-代数 $\mathcal{G}_1 \subseteq \mathcal{G}_2$，那么 $\mathcal{G}_1$ 表示的信息比 $\mathcal{G}_2$ 更少或更粗略，$\mathcal{G}_2$ 则包含 $\mathcal{G}_1$ 的所有信息并且还可能有额外信息。

那么在迭代期望定律中:  
$$
  E\bigl[E[X \mid \mathcal{G}_2]\bigr] \;=\; E[X] \quad \text{且} \quad
  E\bigl[E[X \mid \mathcal{G}_2] \;\bigm|\; \mathcal{G}_1\bigr]
  \;=\;
  E[X \mid \mathcal{G}_1].
$$
  也就是说，当你先在更细的 $\sigma$-代数 $\mathcal{G}_2$ 上做完条件期望，再回到更粗的 $\mathcal{G}_1$ 上取期望时，最终效果就和直接在更粗的 $\mathcal{G}_1$ 上做条件期望一样。这可以直观地理解为“如果已经在更大信息集 $\mathcal{G}_2$ 上做了条件化，再忽略掉那部分额外信息（回到 $\mathcal{G}_1$）时，就会得到与直接在 $\mathcal{G}_1$ 上做条件化相同的结果”。

# 2.统计学复习


