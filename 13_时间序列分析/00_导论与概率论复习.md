
整门课分为四个部分

1. ARMA
2. ARCH,GARCH
3. VAR
4. Nonstationary time series

# 1.概率论复习

## 1.1 概率空间

一个概率空间是一个三元组 $(S, \mathbb{B}, P)$，其中：

- $S$ 是样本空间（sample space），对应于基础随机实验的所有可能结果。
- $\mathbb{B}$ 是 $S$ 的 **$\sigma$-代数**（$\sigma$-field），即 $S$ 的子集的集合，这些子集称为**事件**（events）。
- $P: \mathbb{B} \to [0,1]$ 是**概率测度**（probability measure），用于分配事件的概率。

>[!example] 示例：抛硬币（Coin Throwing）
>假设：
>- $S = \{-1,1\}$，表示两种可能的结果（例如 $-1$ 代表正面，$1$ 代表反面）。
>- $\mathbb{B} = \{\emptyset, S, \{1\}, \{-1\} \}$，表示事件集合，包括空集、全集以及单个事件 $\{1\}$ 和 $\{-1\}$。
>- 概率分布如下：
  $$ P(x = -1) = P(x = 1) = \frac{1}{2} $$
  这描述了一个**公平抛硬币**的概率空间，其中 $x = -1$ 和 $x = 1$ 发生的概率相等，均为 $\frac{1}{2}$。

* 拓展:

Martingale pricing
Black ——Scholes
girsanov theorem
想学的自己搜吧

## 1.2  **Probability densities and distributions (pmf/pdf, CDF)**

离散与连续型随机变量。随机变量 $X$ 的累积分布函数 (CDF) 定义为：

$$
F_{X}(x) = P\bigl(X \le x\bigr) \quad \forall  x \in \mathbb{R}.
$$

## 1.3 **Expectation and population moments**

假设 $X$ 是一个具有概率质量函数或概率密度函数  $f_X(x)$的随机变量。则可测函数$g(x)$的期望定义为：
$$
E(g(X)) = \int_{-\infty}^{\infty} g(x)dF_X(x).
$$
当$g(X) = X$时，这是第一矩（均值）。

## 1.4联合分布与独立性

随机变量 $X$ 和 $Y$ 的联合 CDF 定义如下：

$$
F_{X,Y}(x,y) = P(X \le x, \, Y \le y) = P(X \le x \cap Y \le y),
$$

对于任意 $(x,y) \in \mathbb{R}^2$。当且仅当

$$
F_{X,Y}(x,y) = F_X(x)\,F_Y(y),
$$

对所有 $(x,y) \in \mathbb{R}^2$ 都成立时，$X$ 和 $Y$ 独立。

## 1.5迭代期望定理

### 1.5.1迭代期望定理的定义

>[!note] 迭代期望定义
>在一个概率空间中，若有两个子-$\sigma$-代数 $\mathcal{G}_1 \subseteq \mathcal{G}_2 \subseteq \mathcal{B}$，并且给定一个随机变量 $X$，则有
>$$
>E\bigl[E[X \mid \mathcal{G}_2] \mid \mathcal{G}_1\bigr] = E[X \mid \mathcal{G}_1].
>$$

>[!example] 示例
>==较小的子-$\sigma$-代数主导==
>直觉：较小的子 $\sigma$-代数起支配作用！
>* 示例 1
>考虑回归模型$Y = X\beta + \varepsilon$。假设$E(\varepsilon \mid X) = 0$比$E(\varepsilon) = 0$或$E(X\varepsilon) = 0$更强，因为前者蕴含后者。
>* 示例 2
>在宏观经济学或金融学中，对于跨期世代模型（OLG），我们通常使用性质$E_t(X) = E_{t+1}(X)$，其中 $E_t$ 表示在时间 $t$ 之前的信息（$\sigma$-代数）条件下的期望。

这里讨论的核心是「条件期望」(conditional expectation)以及它的「塔性质」(tower property)——也可以称作「迭代法则」(law of iterated expectations)。简单来说，**当你在一个更“粗”(信息更少)的σ-代数上取条件期望时，这个操作可以“统辖”(dominate)在更“细”(信息更多)的σ-代数上所做的条件期望**。

### **1.5.2. 回归模型中的例子**

在经典的线性回归模型中，我们通常写作：
$$
Y = X\beta + \varepsilon,
$$
一个常见的假设是
$$
E(\varepsilon \mid X) = 0.
$$
这表示给定任意的 $X$，误差项 $\varepsilon$的条件期望都是 0。为什么说它比下列两个假设更强呢？
1. $E(\varepsilon) = 0$
2. $E(X\varepsilon) = 0$

因为如果对所有的 $X$ 都有$E(\varepsilon \mid X) = 0,$那么把上式两边取全期望(不再条件于 $X$)，自然就得到$E(\varepsilon) = 0.$

另外，如果你把 $X$ 乘进上式(并再取期望)，也能得到$E(X\varepsilon) = 0.$
所以，**“条件期望为 0”** 这一假设**自动蕴含**了“无条件期望为 0”和“协方差为 0”这两个结论。换句话说，**条件期望为 0 更强**，因为它能推出后两者。

**直观理解**：

• 若只知道 $E(\varepsilon) = 0$，这只是说“从整体上看”误差项平均值为 0；
• 若只知道 $E(X\varepsilon) = 0$这只是说误差项和解释变量“整体不相关”；
• 而 $E(\varepsilon \mid X) = 0$ 则更严格：它要求无论你拿到什么样的 $X$(信息更多)，误差项都没有系统偏差。

- **子 $\sigma$-代数**可以理解为“包含的信息量”不同的视角：  
  若有两个子 $\sigma$-代数 $\mathcal{G}_1 \subseteq \mathcal{G}_2$，那么 $\mathcal{G}_1$ 表示的信息比 $\mathcal{G}_2$ 更少或更粗略，$\mathcal{G}_2$ 则包含 $\mathcal{G}_1$ 的所有信息并且还可能有额外信息。

那么在迭代期望定律中:  
$$
  E\bigl[E[X \mid \mathcal{G}_2]\bigr] \;=\; E[X] \quad \text{且} \quad
  E\bigl[E[X \mid \mathcal{G}_2] \;\bigm|\; \mathcal{G}_1\bigr]
  \;=\;
  E[X \mid \mathcal{G}_1].
$$
  也就是说，当你先在更细的 $\sigma$-代数 $\mathcal{G}_2$ 上做完条件期望，再回到更粗的 $\mathcal{G}_1$ 上取期望时，最终效果就和直接在更粗的 $\mathcal{G}_1$ 上做条件期望一样。这可以直观地理解为“如果已经在更大信息集 $\mathcal{G}_2$ 上做了条件化，再忽略掉那部分额外信息（回到 $\mathcal{G}_1$）时，就会得到与直接在 $\mathcal{G}_1$ 上做条件化相同的结果”。

# 2.统计学复习

## 2.1统计学概念复习

## 2.1.1统计量

统计量和检验统计量都是统计量.

## 2.1.2 收敛

==依概率收敛强于依分布收敛==,
如果极限是常数,依概率收敛和依分布收敛是一样的

#### (1)依分布收敛


使用中心极限定理证明.

#### (2)依概率收敛

## 2.2 slutsky theorem

>[!note] slutsky theorem定义
>假设 $X_n \xrightarrow{d} X$ 且 $c_n \xrightarrow{p} c$，其中 $c$ 是一个常数。那么我们有：
>- $X_n \pm c_n \xrightarrow{d} X \pm c$
>- $X_n c_n \xrightarrow{d} Xc$
>- $\frac{X_n}{c_n} \xrightarrow{d} \frac{X}{c}$，当 $c \neq 0$
>- **示例**: 在中心极限定理（CLT）中，用其一致估计量替换 $\sigma$。

在计量中,样本方差估计总体方差,然后使用slutsky theorem 可以得到t检验统计量
$$t = \frac{\sqrt n \bar{X}_n}{\sqrt{\frac{1}{n} \sum (X_i - \bar{X}_n)^2}}
 \xrightarrow{d} N(0,1)$$

