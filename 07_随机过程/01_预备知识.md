1. 简要回顾一下概率论中与本课程有关的基本概念:随机试验样本空间事件概率随机变量等.
2. 随机过程的概念.分类

# 概率论有关概念

## 随机试验

对随机现象的观察记录试验统称为随机试验
它具有以下特性:
1. 可重复性:可以在相同条件下重复进行
2. 可观察性:事先知道可能出现的结果
3. 随机性:进行试验前并不知道哪个试验结果会发生

## 样本空间

随机试验E的所有结果构成的集合称为E的样本空间,记为Ω={e}.

### 样本点

称Ω中的元素e为基本事件或样本点

## 随机事件

称Ω的子集A为E的随机事件A,当且仅当A所包含的一个样本点发生称事件A发生

### 必然事件

如果将Ω亦视作事件,则每次试验Ω总是发生,故又称Ω为必然事件.

### 不可能事件

记Φ为不可能事件,Φ不包含任何样本点.

## 事件关系

### 包含与相等

![[Pasted image 20241111104407.png]]

## 事件运算

### 和运算

A与B的和事件,记为 A u B表示A与B至少有一发生.
![[Pasted image 20241111105805.png]]

### 积运算

A与B的积事件Y记为 A n B , A · B , AB.表示A与B同时发生.
当AB=Φ时Y称事件A与B不相容

![[Pasted image 20241111105815.png]]

### 逆运算

![[Pasted image 20241111110612.png]]

### 德·摩根De Morgan法则(和交关系式)

![[Pasted image 20241111110745.png]]

## 古典概率

随机试验中一切可能结果是有限多个.每个结果出现的可能性是相等的.则事件A发生的概率可表示为:

![[Pasted image 20241111111314.png]]

## 几何概率

计算无穷个基本事件的情形.样本点具有均匀分布的性质.设用L(Ω) 作为区域Ω大小的量度Y而区域Ω中任意可能出现的小区域A的量度用L(A)表示.则事件A(或某一区域)发生的概率表示为:

![[Pasted image 20241111111833.png]]

## 统计概率

用于计算前两种随机概率概括不了的随机事件概率.用事件的频率近似地去表达事件的概率,eg:抛硬币出现正面的频率

# 条件概率

## 条件概率定义

![[Pasted image 20241202143143.png]]

$$P(B|A)= \frac{P(AB)}{P(A)}$$

## 乘法公式

$$P(AB)=P(A)·P(B|A)$$

## 全概率公式

### 完备事件组

![[Pasted image 20241202153134.png]]

## **全概率公式**（The Law of Total Probability）

是概率论中的一个基本公式，用于将一个复杂事件的概率分解成若干个互不相容事件上的概率求和。

**定义**

假设有一个样本空间 $S$，事件 $A$ 和一组互不相容且完备的事件 $B_1, B_2, \dots, B_n$（即 $\bigcup_{i=1}^n B_i = S$ 且 $B_i \cap B_j = \emptyset$ 当 $i \neq j$）满足：

$$P(B_i) > 0 \quad \forall i \in {1, 2, \dots, n}$$

  

则事件 $A$ 的概率可以表示为：

$$P(A) = \sum_{i=1}^n P(A \cap B_i)$$

根据条件概率的定义，$P(A \cap B_i) = P(A \mid B_i)P(B_i)$，所以公式也可以写成：

$$P(A) = \sum_{i=1}^n P(A \mid B_i)P(B_i)$$

通过全概率公式，可以将复杂概率问题分解成多个简单部分来解决。

## Bayes公式

**贝叶斯公式**（Bayes’ Theorem）是概率论中重要的公式，用于在已知条件概率的情况下计算逆条件概率。它的核心思想是通过先验概率和条件概率来更新对事件发生的概率的认知。

假设事件 $A$ 和 $B$ 满足 $P(B) > 0$，贝叶斯公式可以表示为：

$$

P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}

$$

其中：

• $P(A \mid B)$：在 $B$ 发生的条件下，事件 $A$ 发生的后验概率（Posterior Probability）。

• $P(B \mid A)$：在 $A$ 发生的条件下，事件 $B$ 发生的条件概率。

• $P(A)$：事件 $A$ 的先验概率（Prior Probability）。

• $P(B)$：事件 $B$ 的边际概率（Marginal Probability），可以用全概率公式计算：

$$

P(B) = \sum_{i} P(B \mid A_i)P(A_i)

$$

**理解**

贝叶斯公式的关键是将已知的条件概率 $P(B \mid A)$ 和先验概率 $P(A)$ 转化为逆条件概率 $P(A \mid B)$。它反映了如何根据新证据（$B$）更新对事件（$A$）发生的概率的估计。

**例子**

**例子：疾病诊断**

假设一个测试用于检测某种疾病，定义如下：

• $A$：某人患有这种疾病。

• $B$：测试结果为阳性。

已知数据：

• 该疾病的患病率：$P(A) = 0.01$。
• 测试的灵敏度（准确检出患病者的概率）：$P(B \mid A) = 0.95$。
• 测试的特异性（准确检出未患病者的概率）：$P(B^c \mid A^c) = 0.90$，其中 $B^c$ 表示测试结果为阴性，$A^c$ 表示未患病。

要计算某人测试阳性后，实际患病的概率 $P(A \mid B)$。

  

**步骤 1：计算 $P(B)$（边际概率）**

$$

P(B) = P(B \mid A)P(A) + P(B \mid A^c)P(A^c)

$$

其中：

• $P(B \mid A^c) = 1 - P(B^c \mid A^c) = 1 - 0.90 = 0.10$

• $P(A^c) = 1 - P(A) = 0.99$

  

代入数据：

$$

P(B) = 0.95 \times 0.01 + 0.10 \times 0.99 = 0.0095 + 0.099 = 0.1085

$$

  

**步骤 2：代入贝叶斯公式**

$$

P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}

$$

代入数据：

$$

P(A \mid B) = \frac{0.95 \times 0.01}{0.1085} \approx 0.0876

$$

  

**结果**

某人测试阳性后，实际患病的概率为 $8.76percent$。

在概率论和统计学中，**先验概率**和**后验概率**是贝叶斯统计中的两个核心概念，用于描述信息更新前后的概率。

###  **先验概率（Prior Probability）**

**定义**：先验概率是基于已有知识或经验，对某个事件发生的初始估计概率。

• 它表示在没有引入额外证据之前，对事件可能性的一种主观判断或客观估计。
• 通常来源于历史数据、经验或假设。
• 在贝叶斯公式中，用 $P(A)$ 表示，表示在观察证据 $B$ 之前，事件 $A$ 的概率。

**例子**

1. **医学领域**：

• 某种疾病的患病率是 $1%$。这是基于历史数据计算得到的先验概率。

• $P(A) = 0.01$，这里 $A$ 是“患病”的事件。

2. **经济预测**：

• 根据过去的市场行为，预计某支股票价格上涨的概率是 70%，这就是先验概率。

### **后验概率（Posterior Probability）**

**定义**：后验概率是在观察到额外信息或证据后，对事件发生概率的更新。

• 它表示结合新的证据后，重新评估某事件的可能性。
• 在贝叶斯公式中，用 $P(A \mid B)$ 表示，表示在证据 $B$ 出现后，事件 $A$ 的概率。
• 后验概率是对先验概率的调整，结合了新的数据或信息。

**例子**

1. **医学领域**：

• 某人进行了疾病检测，测试结果为阳性。

• 根据贝叶斯公式重新计算的概率 $P(A \mid B)$，表示在测试阳性这一新证据下，该人实际患病的概率。

2. **经济预测**：

• 如果观察到股市整体走势上升，更新后某支股票价格上涨的概率变为 85%。这就是后验概率。

# 事件的独立性

在概率论中，**事件的独立性**是描述两个或多个事件之间是否存在关联的一种特性。如果事件之间没有任何关联，即一个事件的发生不会影响另一个事件发生的概率，则这些事件被称为独立事件。

## **定义**

两个事件 $A$ 和 $B$ 被称为独立事件，当且仅当：

$$

P(A \cap B) = P(A)P(B)

$$

**解释**：

• $P(A \cap B)$ 表示事件 $A$ 和事件 $B$ 同时发生的概率。

• 如果 $P(A \cap B)$ 等于 $P(A)$ 和 $P(B)$ 的乘积，则 $A$ 和 $B$ 的发生是完全独立的，没有任何交互或依赖关系。

  

## **条件概率定义**

另一个等价的定义是基于条件概率：

$$

P(A \mid B) = P(A)

$$

或

$$

P(B \mid A) = P(B)

$$

**解释**：事件 $A$ 的发生概率不因事件 $B$ 的发生与否而改变，反之亦然。  

**举例**

1. **投掷硬币**

• 第一次投掷硬币是正面（事件 $A$）。

• 第二次投掷硬币是正面（事件 $B$）。

• 因为每次投掷硬币的结果互不影响，所以 $A$ 和 $B$ 是独立事件。

验证：

• $P(A) = 0.5$, $P(B) = 0.5$。

• $P(A \cap B) = P(\text{第一次正面且第二次正面}) = 0.5 \times 0.5 = 0.25$。

• 满足独立性条件：$P(A \cap B) = P(A)P(B)$。

2. **掷骰子**

• 掷一次骰子，事件 $A$ 是掷出偶数，事件 $B$ 是掷出的点数大于 3。

• 偶数有 ${2, 4, 6}$，点数大于 3 的有 ${4, 5, 6}$，同时满足 $A$ 和 $B$ 的是 ${4, 6}$。

• $P(A) = \frac{3}{6} = 0.5$, $P(B) = \frac{3}{6} = 0.5$。

• $P(A \cap B) = \frac{2}{6} = \frac{1}{3}$。

• 验证：$P(A \cap B) \neq P(A)P(B)$，因此 $A$ 和 $B$ 不是独立事件  

## **多个事件的独立性**

  

如果有多个事件 $A_1, A_2, \dots, A_n$，这些事件是**相互独立的**，需满足以下条件：

1. 任意两个事件是独立的，即对于任意 $i \neq j$：

$$

P(A_i \cap A_j) = P(A_i)P(A_j)

$$

2. 任意多个事件的联合概率等于每个事件概率的乘积，例如对于三个事件 $A_1, A_2, A_3$：

$$

P(A_1 \cap A_2 \cap A_3) = P(A_1)P(A_2)P(A_3)

$$

**注意：**

• **两两独立不等于相互独立**：即使任意两个事件之间独立，也不一定意味着所有事件之间相互独立。

**独立性与不独立的对比**

**特性** **独立事件** **不独立事件**

定义 $P(A \cap B) = P(A)P(B)$ $P(A \cap B) \neq P(A)P(B)$

条件概率 $P(A \mid B) = P(A)$ $P(A \mid B) \neq P(A)$

影响 一个事件发生不影响另一个事件 一个事件发生可能影响另一个事件

**独立性的重要性**

1. **简化计算**：在多个事件独立的情况下，可以通过概率的乘法规则快速计算联合概率。

• 如 $P(A_1 \cap A_2 \cap A_3) = P(A_1)P(A_2)P(A_3)$。

2. **建模基础**：独立性假设是许多概率模型（如朴素贝叶斯分类器）的核心前提。

3. **统计学应用**：样本的独立性是许多统计推断方法的前提，如参数估计和假设检验。
