
# 本章内容大纲

 **一、概率论预备知识**

**1. 随机试验与事件**

• **随机试验的定义**：
• 可重复性
• 可观察性
• 随机性

• **样本空间与随机事件**：

• 样本空间 $\Omega$
• 事件 $A \subseteq \Omega$
• **事件运算**：
• 包含、交、并、补
• 德摩根法则

**2. 概率的类型**

• **古典概率**：有限样本空间内事件概率
• **几何概率**：连续样本空间事件概率
• **统计概率**：基于事件频率的概率近似

**3. 条件概率与贝叶斯公式**

• **条件概率**：$P(B|A) = \frac{P(A \cap B)}{P(A)}$
• **全概率公式**：$P(A) = \sum_{i=1}^n P(B_i)P(A|B_i)$
• **贝叶斯公式**：$P(B_i|A) = \frac{P(B_i)P(A|B_i)}{\sum_{j=1}^n P(B_j)P(A|B_j)}$

**二、随机变量**

**1. 随机变量的分类**

• **离散型随机变量**：可能取值有限或可列无穷
• **连续型随机变量**：值在连续区间上

**2. 随机变量的分布**

• **概率分布函数**：$F(x) = P(X \leq x)$
• **概率密度函数**：$f(x) = \frac{d}{dx}F(x)$

**3. 常见分布**

• **离散分布**：0-1分布、二项分布、泊松分布
• **连续分布**：均匀分布、正态分布、指数分布

**三、多维随机变量**

**1. 联合分布与边际分布**

• **联合分布函数**：$F_{XY}(x,y) = P(X \leq x, Y \leq y)$
• **边际分布函数**：

$$

F_X(x) = \lim_{y \to \infty} F_{XY}(x, y)

$$

**2. 条件分布与独立性**

• **条件分布**：$P(X \leq x | Y = y)$
• **独立性**：若 $P(X \leq x, Y \leq y) = P(X \leq x)P(Y \leq y)$，则 $X$ 和 $Y$ 独立。

**四、随机变量的数字特征**

**1. 数学期望**

• 定义：
• 离散型随机变量：$E[X] = \sum_{i} x_i P(X = x_i)$
• 连续型随机变量：$E[X] = \int_{-\infty}^{\infty} x f(x)dx$
• 性质：线性性、非负性

**2. 方差与协方差**

• **方差**：$Var(X) = E[(X - E[X])^2]$
• **协方差**：$Cov(X, Y) = E[(X - E[X])(Y - E[Y])]$

**3. 相关系数**

• 定义：$\rho_{XY} = \frac{Cov(X, Y)}{\sqrt{Var(X)Var(Y)}}$
• 范围：$-1 \leq \rho_{XY} \leq 1$

**五、生成函数与特征函数**

**1. 生成函数**

• 定义：离散随机变量的生成函数 $G_X(z) = E[z^X]$
• 应用：求和概率分布，卷积性质

**2. 特征函数**

• 定义：$\phi_X(t) = E[e^{itX}]$
• 性质：特征函数包含分布的全部信息。

------------------------------------

# 一. 概率论有关概念

## 随机试验

对随机现象的观察记录试验统称为随机试验
它具有以下特性:
1. 可重复性:可以在相同条件下重复进行
2. 可观察性:事先知道可能出现的结果
3. 随机性:进行试验前并不知道哪个试验结果会发生

## 样本空间

随机试验E的所有结果构成的集合称为E的样本空间,记为Ω={e}.

### 样本点

称Ω中的元素e为基本事件或样本点

## 随机事件

称Ω的子集A为E的随机事件A,当且仅当A所包含的一个样本点发生称事件A发生

### 必然事件

如果将Ω亦视作事件,则每次试验Ω总是发生,故又称Ω为必然事件.

### 不可能事件

记Φ为不可能事件,Φ不包含任何样本点.

## 事件关系

### 包含与相等

![[Pasted image 20241111104407.png]]

## 事件运算

### 和运算

A与B的和事件,记为 A u B表示A与B至少有一发生.
![[Pasted image 20241111105805.png]]

### 积运算

A与B的积事件Y记为 A n B , A · B , AB.表示A与B同时发生.
当AB=Φ时Y称事件A与B不相容

![[Pasted image 20241111105815.png]]

### 逆运算

![[Pasted image 20241111110612.png]]

### 德·摩根De Morgan法则(和交关系式)

![[Pasted image 20241111110745.png]]

## 古典概率

随机试验中一切可能结果是有限多个.每个结果出现的可能性是相等的.则事件A发生的概率可表示为:

![[Pasted image 20241111111314.png]]

## 几何概率

计算无穷个基本事件的情形.样本点具有均匀分布的性质.设用L(Ω) 作为区域Ω大小的量度Y而区域Ω中任意可能出现的小区域A的量度用L(A)表示.则事件A(或某一区域)发生的概率表示为:

![[Pasted image 20241111111833.png]]

## 统计概率

用于计算前两种随机概率概括不了的随机事件概率.用事件的频率近似地去表达事件的概率,eg:抛硬币出现正面的频率

## 条件概率

### 条件概率定义

![[Pasted image 20241202143143.png]]

$$P(B|A)= \frac{P(AB)}{P(A)}$$

### 乘法公式

$$P(AB)=P(A)·P(B|A)$$

### 全概率公式

#### 完备事件组

![[Pasted image 20241202153134.png]]

### **全概率公式**（The Law of Total Probability）

是概率论中的一个基本公式，用于将一个复杂事件的概率分解成若干个互不相容事件上的概率求和。

**定义**

假设有一个样本空间 $S$，事件 $A$ 和一组互不相容且完备的事件 $B_1, B_2, \dots, B_n$（即 $\bigcup_{i=1}^n B_i = S$ 且 $B_i \cap B_j = \emptyset$ 当 $i \neq j$）满足：

$$P(B_i) > 0 \quad \forall i \in {1, 2, \dots, n}$$

  

则事件 $A$ 的概率可以表示为：

$$P(A) = \sum_{i=1}^n P(A \cap B_i)$$

根据条件概率的定义，$P(A \cap B_i) = P(A \mid B_i)P(B_i)$，所以公式也可以写成：

$$P(A) = \sum_{i=1}^n P(A \mid B_i)P(B_i)$$

通过全概率公式，可以将复杂概率问题分解成多个简单部分来解决。

### Bayes公式

**贝叶斯公式**（Bayes’ Theorem）是概率论中重要的公式，用于在已知条件概率的情况下计算逆条件概率。它的核心思想是通过先验概率和条件概率来更新对事件发生的概率的认知。

假设事件 $A$ 和 $B$ 满足 $P(B) > 0$，贝叶斯公式可以表示为：

$$

P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}

$$

其中：

• $P(A \mid B)$：在 $B$ 发生的条件下，事件 $A$ 发生的后验概率（Posterior Probability）。
• $P(B \mid A)$：在 $A$ 发生的条件下，事件 $B$ 发生的条件概率。
• $P(A)$：事件 $A$ 的先验概率（Prior Probability）。
• $P(B)$：事件 $B$ 的边际概率（Marginal Probability），可以用全概率公式计算：

$$

P(B) = \sum_{i} P(B \mid A_i)P(A_i)

$$

**理解**

贝叶斯公式的关键是将已知的条件概率 $P(B \mid A)$ 和先验概率 $P(A)$ 转化为逆条件概率 $P(A \mid B)$。它反映了如何根据新证据（$B$）更新对事件（$A$）发生的概率的估计。

**例子**

**例子：疾病诊断**

假设一个测试用于检测某种疾病，定义如下：

• $A$：某人患有这种疾病。
• $B$：测试结果为阳性。

已知数据：

• 该疾病的患病率：$P(A) = 0.01$。
• 测试的灵敏度（准确检出患病者的概率）：$P(B \mid A) = 0.95$。
• 测试的特异性（准确检出未患病者的概率）：$P(B^c \mid A^c) = 0.90$，其中 $B^c$ 表示测试结果为阴性，$A^c$ 表示未患病。

要计算某人测试阳性后，实际患病的概率 $P(A \mid B)$。

**步骤 1：计算 $P(B)$（边际概率）**

$$
P(B) = P(B \mid A)P(A) + P(B \mid A^c)P(A^c)
$$

其中：

• $P(B \mid A^c) = 1 - P(B^c \mid A^c) = 1 - 0.90 = 0.10$
• $P(A^c) = 1 - P(A) = 0.99$

代入数据：

$$

P(B) = 0.95 \times 0.01 + 0.10 \times 0.99 = 0.0095 + 0.099 = 0.1085

$$

  

**步骤 2：代入贝叶斯公式**

$$

P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}

$$

代入数据：

$$

P(A \mid B) = \frac{0.95 \times 0.01}{0.1085} \approx 0.0876

$$

  

**结果**

某人测试阳性后，实际患病的概率为 $8.76percent$。
在概率论和统计学中，**先验概率**和**后验概率**是贝叶斯统计中的两个核心概念，用于描述信息更新前后的概率。

####  **先验概率（Prior Probability）**

**定义**：先验概率是基于已有知识或经验，对某个事件发生的初始估计概率。

• 它表示在没有引入额外证据之前，对事件可能性的一种主观判断或客观估计。
• 通常来源于历史数据、经验或假设。
• 在贝叶斯公式中，用 $P(A)$ 表示，表示在观察证据 $B$ 之前，事件 $A$ 的概率。

**例子**

1. **医学领域**：

• 某种疾病的患病率是 $1%$。这是基于历史数据计算得到的先验概率。

• $P(A) = 0.01$，这里 $A$ 是“患病”的事件。

2. **经济预测**：

• 根据过去的市场行为，预计某支股票价格上涨的概率是 70%，这就是先验概率。

#### **后验概率（Posterior Probability）**

**定义**：后验概率是在观察到额外信息或证据后，对事件发生概率的更新。

• 它表示结合新的证据后，重新评估某事件的可能性。
• 在贝叶斯公式中，用 $P(A \mid B)$ 表示，表示在证据 $B$ 出现后，事件 $A$ 的概率。
• 后验概率是对先验概率的调整，结合了新的数据或信息。

**例子**

1. **医学领域**：

• 某人进行了疾病检测，测试结果为阳性。

• 根据贝叶斯公式重新计算的概率 $P(A \mid B)$，表示在测试阳性这一新证据下，该人实际患病的概率。

2. **经济预测**：

• 如果观察到股市整体走势上升，更新后某支股票价格上涨的概率变为 85%。这就是后验概率。

## 事件的独立性

在概率论中，**事件的独立性**是描述两个或多个事件之间是否存在关联的一种特性。如果事件之间没有任何关联，即一个事件的发生不会影响另一个事件发生的概率，则这些事件被称为独立事件。

### **定义**

两个事件 $A$ 和 $B$ 被称为独立事件，当且仅当：

$$

P(A \cap B) = P(A)P(B)

$$

**解释**：

• $P(A \cap B)$ 表示事件 $A$ 和事件 $B$ 同时发生的概率。
• 如果 $P(A \cap B)$ 等于 $P(A)$ 和 $P(B)$ 的乘积，则 $A$ 和 $B$ 的发生是完全独立的，没有任何交互或依赖关系。

### **条件概率定义**

另一个等价的定义是基于条件概率：

$$
P(A \mid B) = P(A)
$$

或

$$
P(B \mid A) = P(B)
$$

**解释**：事件 $A$ 的发生概率不因事件 $B$ 的发生与否而改变，反之亦然。  

**举例**

1. **投掷硬币**

• 第一次投掷硬币是正面（事件 $A$）。
• 第二次投掷硬币是正面（事件 $B$）。
• 因为每次投掷硬币的结果互不影响，所以 $A$ 和 $B$ 是独立事件。

验证：

• $P(A) = 0.5$, $P(B) = 0.5$。
• $P(A \cap B) = P(\text{第一次正面且第二次正面}) = 0.5 \times 0.5 = 0.25$。
• 满足独立性条件：$P(A \cap B) = P(A)P(B)$。

2. **掷骰子**

• 掷一次骰子，事件 $A$ 是掷出偶数，事件 $B$ 是掷出的点数大于 3。
• 偶数有 ${2, 4, 6}$，点数大于 3 的有 ${4, 5, 6}$，同时满足 $A$ 和 $B$ 的是 ${4, 6}$。
• $P(A) = \frac{3}{6} = 0.5$, $P(B) = \frac{3}{6} = 0.5$。
• $P(A \cap B) = \frac{2}{6} = \frac{1}{3}$。

• 验证：$P(A \cap B) \neq P(A)P(B)$，因此 $A$ 和 $B$ 不是独立事件  

### **多个事件的独立性**  

如果有多个事件 $A_1, A_2, \dots, A_n$，这些事件是**相互独立的**，需满足以下条件：

1. 任意两个事件是独立的，即对于任意 $i \neq j$：

$$

P(A_i \cap A_j) = P(A_i)P(A_j)

$$

2. 任意多个事件的联合概率等于每个事件概率的乘积，例如对于三个事件 $A_1, A_2, A_3$：

$$

P(A_1 \cap A_2 \cap A_3) = P(A_1)P(A_2)P(A_3)

$$

**注意：**

• **两两独立不等于相互独立**：即使任意两个事件之间独立，也不一定意味着所有事件之间相互独立。

### **独立性与不独立的对比**

**特性**                   **独立事件**                                                  **不独立事件**

定义                  $P(A \cap B) = P(A)P(B)$                        $P(A \cap B) \neq P(A)P(B)$

条件概率            $P(A \mid B) = P(A)$                           $P(A \mid B) \neq P(A)$

影响            一个事件发生不影响另一个事件          一个事件发生可能影响另一个事件

**独立性的重要性**

1. **简化计算**：在多个事件独立的情况下，可以通过概率的乘法规则快速计算联合概率。

• 如 $P(A_1 \cap A_2 \cap A_3) = P(A_1)P(A_2)P(A_3)$。

2. **建模基础**：独立性假设是许多概率模型（如朴素贝叶斯分类器）的核心前提。

3. **统计学应用**：样本的独立性是许多统计推断方法的前提，如参数估计和假设检验。



# 二. 随机变量

## 1. 随机变量的定义

==设$(Ω, F, P)$是概率空间,$X=X(e)$是定义在$Ω$上的实函数.如果对任意实数$x$，$\{e:X(e) \leq x\} \in F$ 则称$X(e)$是$F$上的随机变量.==

### (1)$(Ω, F, P)$是概率空间

#### 1). $Ω$(样本空间)

• $Ω$是一个集合，包含所有可能的实验结果。

• 例如：

• 如果抛一枚硬币，$Ω = {\text{正面}, \text{反面}}$。
• 如果掷一颗骰子，$Ω = {1, 2, 3, 4, 5, 6}$。
• $Ω$表示所有可能发生的结果，是概率论的基础。

#### **2). $F$（事件的集合/$σ$-代数）**

• $F$是$Ω$的一个子集，表示可以“度量概率”的事件集合。
• 一个事件是样本空间中的一些特定结果的集合。

• 例如：
• 对于硬币，事件可以是“正面朝上”，即$F = {\text{正面}}$，或“反面朝上”，即$F = {\text{反面}}$。
• 对于骰子，事件可以是“掷出偶数”，即$F = {2, 4, 6}$。
• 数学上，$F$需要满足某些条件（如包含全集、闭合性等），初学时可以简单理解为“描述感兴趣事件的集合”。

#### **3). $P$（概率测度）**

• $P$是一个函数，用来为$F$中的每个事件分配概率，描述事件发生的可能性。
• $P$需要满足以下性质：
1. **非负性**：对任意事件$A \in F$，$P(A) \geq 0$。
2. **规范性**：$P(Ω) = 1$（样本空间的概率总和为1）。
3. **可加性**：如果$A_1, A_2, \dots$是互不重叠的事件，则有：

$$P(A_1 \cup A_2 \cup \dots) = P(A_1) + P(A_2) + \dots$$

例如：

• 抛一枚均匀的硬币，概率分布是：
• $P({\text{正面}}) = 0.5$
• $P({\text{反面}}) = 0.5$
• 掷一颗均匀骰子，概率分布是：
• $P({1}) = \frac{1}{6}$
• $P({2, 4, 6}) = \frac{1}{2}$（偶数的概率）

### (2)$X=X(e)$是定义在$Ω$上的实函数

• $X$表示随机变量，它是一个函数，把样本空间中的元素（$e$，即样本）映射到实数空间。
• 换句话说，随机变量把复杂的实验结果（$e$）用一个实数来表示。

• 例如，抛硬币：
• $Ω = {\text{正面}, \text{反面}}$。
• 定义随机变量$X$为：“正面记作1，反面记作0”。这就是一个函数映射：
• 如果$e = \text{正面}$，$X(e) = 1$。
• 如果$e = \text{反面}$，$X(e) = 0$。

### (3). 如果对任意实数$x$，$\{e:X(e) \leq x\} \in F$

这句话的意思是：

• 随机变量$X$的值**小于等于某个实数$x$的所有样本事件组成的集合${e : X(e) \leq x}$，必须是事件集合$F$中的一个元素。

**通俗解释**

• ${e : X(e) \leq x}$是一个集合，表示“实验结果$e$”中，哪些事件使得随机变量$X$的值小于等于$x$。
• 这个集合必须是“可测的”，也就是它必须属于$F$，这样概率$P$才能被定义。

**举例说明**

1. 假设我们掷一颗骰子，样本空间$Ω = {1, 2, 3, 4, 5, 6}$。
2. 定义随机变量$X(e) = e$，表示掷出的点数。
3. 如果我们关心“掷出的点数小于等于3”的事件集合${e : X(e) \leq 3}$，那么这个集合就是${1, 2, 3}$。
4. 这个集合${1, 2, 3}$需要属于$F$，我们才能给它赋一个概率，比如$P({1, 2, 3}) = \frac{3}{6} = 0.5$。

这表明，随机变量$X$的定义必须依赖于$F$，这样$X$的值和概率才有意义。

### (4)则称$X(e)$是$F$上的随机变量

**这句话的意义**

只要随机变量$X$满足以下条件：

1. 它是从$Ω$到实数的映射；
2. 对任何实数$x$，集合${e : X(e) \leq x}$都在事件集合$F$中；

我们就可以说：

• $X$是一个随机变量；
• 它是定义在事件集合$F$上的，也就是$F$保证了$X$的取值可以被描述并赋予概率。

**再通俗一点解释**

随机变量$X$的定义要求：

1. 它能把样本空间中的结果（例如骰子的点数）映射为一个实数；
2. 它的分布（例如“点数小于等于3”）可以用$F$中的事件描述，从而分配概率。

**更直观的例子**

• 假设你有一个随机变量$X$，表示“掷骰子的点数”。
• 如果$F$是一个非常简单的集合，例如${空集, Ω}$，那么它不能描述复杂的事件（比如“点数小于等于3”）。
• 只有当$F$包含了所有可能的子集（例如${1, 2, 3}$这样的事件集合），我们才能说$X$是定义在$F$上的随机变量。

## 2. 随机变量的分类

### 累积分布函数（CDF）

累积分布函数$F(x)$定义为随机变量$X$取值小于或等于某实数$x$的概率：

$$
F(x) = P(e : X(e) \leq x)
$$

这里$x$可以取任何实数值，从$-\infty$到$\infty$。

**主要性质**

1. **右连续性**：$F(x)$是右连续的，意味着在$x$的任意右侧点，函数值$F(x)$趋向于该点的函数值。换句话说，当我们从左边逼近$x$时，$F(x)$的值不会突变。
2. **取值范围**：$0 \leq F(x) \leq 1$。这表示$F(x)$作为概率，其值必须在0和1之间，包括0和1。
3. **概率计算**：$P(x_1 < X \leq x_2) = F(x_2) - F(x_1)$。这个性质用于计算随机变量$X$取值在某个区间$(x_1, x_2]$的概率。
4. **增函数性**：$F(x)$是一个非递减函数。这意味着如果$x_1 \leq x_2$，那么$F(x_1) \leq F(x_2)$。这反映了随机变量$X$取值越大，小于或等于这个值的概率不会减小。

### 1)离散型随机变量

只取有限个数值或可列无穷多个值

### 2)连续型随机变量

从原样本空间到新样本空间的映射是 某一个范围是一段(或几段)实线(也可能是整个坐标轴),随机变量可以取某一区间中的任一数.

