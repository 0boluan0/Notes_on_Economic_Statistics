
# 本章内容大纲

 **一、概率论预备知识**

**1. 随机试验与事件**

• **随机试验的定义**：
• 可重复性
• 可观察性
• 随机性

• **样本空间与随机事件**：

• 样本空间 $\Omega$
• 事件 $A \subseteq \Omega$
• **事件运算**：
• 包含、交、并、补
• 德摩根法则

**2. 概率的类型**

• **古典概率**：有限样本空间内事件概率
• **几何概率**：连续样本空间事件概率
• **统计概率**：基于事件频率的概率近似

**3. 条件概率与贝叶斯公式**

• **条件概率**：$P(B|A) = \frac{P(A \cap B)}{P(A)}$
• **全概率公式**：$P(A) = \sum_{i=1}^n P(B_i)P(A|B_i)$
• **贝叶斯公式**：$P(B_i|A) = \frac{P(B_i)P(A|B_i)}{\sum_{j=1}^n P(B_j)P(A|B_j)}$

**二、随机变量**

**1. 随机变量的分类**

• **离散型随机变量**：可能取值有限或可列无穷
• **连续型随机变量**：值在连续区间上

**2. 随机变量的分布**

• **概率分布函数**：$F(x) = P(X \leq x)$
• **概率密度函数**：$f(x) = \frac{d}{dx}F(x)$

**3. 常见分布**

• **离散分布**：0-1分布、二项分布、泊松分布
• **连续分布**：均匀分布、正态分布、指数分布

**三、多维随机变量**

**1. 联合分布与边际分布**

• **联合分布函数**：$F_{XY}(x,y) = P(X \leq x, Y \leq y)$
• **边际分布函数**：

$$

F_X(x) = \lim_{y \to \infty} F_{XY}(x, y)

$$

**2. 条件分布与独立性**

• **条件分布**：$P(X \leq x | Y = y)$
• **独立性**：若 $P(X \leq x, Y \leq y) = P(X \leq x)P(Y \leq y)$，则 $X$ 和 $Y$ 独立。

**四、随机变量的数字特征**

**1. 数学期望**

• 定义：
• 离散型随机变量：$E[X] = \sum_{i} x_i P(X = x_i)$
• 连续型随机变量：$E[X] = \int_{-\infty}^{\infty} x f(x)dx$
• 性质：线性性、非负性

**2. 方差与协方差**

• **方差**：$Var(X) = E[(X - E[X])^2]$
• **协方差**：$Cov(X, Y) = E[(X - E[X])(Y - E[Y])]$

**3. 相关系数**

• 定义：$\rho_{XY} = \frac{Cov(X, Y)}{\sqrt{Var(X)Var(Y)}}$
• 范围：$-1 \leq \rho_{XY} \leq 1$

**五、生成函数与特征函数**

**1. 生成函数**

• 定义：离散随机变量的生成函数 $G_X(z) = E[z^X]$
• 应用：求和概率分布，卷积性质

**2. 特征函数**

• 定义：$\phi_X(t) = E[e^{itX}]$
• 性质：特征函数包含分布的全部信息。

------------------------------------

# 一. 概率论有关概念

## 随机试验

对随机现象的观察记录试验统称为随机试验
它具有以下特性:
1. 可重复性:可以在相同条件下重复进行
2. 可观察性:事先知道可能出现的结果
3. 随机性:进行试验前并不知道哪个试验结果会发生

## 样本空间

随机试验E的所有结果构成的集合称为E的样本空间,记为Ω={e}.

### 样本点

称Ω中的元素e为基本事件或样本点

## 随机事件

称Ω的子集A为E的随机事件A,当且仅当A所包含的一个样本点发生称事件A发生

### 必然事件

如果将Ω亦视作事件,则每次试验Ω总是发生,故又称Ω为必然事件.

### 不可能事件

记Φ为不可能事件,Φ不包含任何样本点.

## 事件关系

### 包含与相等

![[Pasted image 20241111104407.png]]

## 事件运算

### 和运算

A与B的和事件,记为 A u B表示A与B至少有一发生.
![[Pasted image 20241111105805.png]]

### 积运算

A与B的积事件Y记为 A n B , A · B , AB.表示A与B同时发生.
当AB=Φ时Y称事件A与B不相容

![[Pasted image 20241111105815.png]]

### 逆运算

![[Pasted image 20241111110612.png]]

### 德·摩根De Morgan法则(和交关系式)

![[Pasted image 20241111110745.png]]

## 古典概率

随机试验中一切可能结果是有限多个.每个结果出现的可能性是相等的.则事件A发生的概率可表示为:

![[Pasted image 20241111111314.png]]

## 几何概率

计算无穷个基本事件的情形.样本点具有均匀分布的性质.设用L(Ω) 作为区域Ω大小的量度Y而区域Ω中任意可能出现的小区域A的量度用L(A)表示.则事件A(或某一区域)发生的概率表示为:

![[Pasted image 20241111111833.png]]

## 统计概率

用于计算前两种随机概率概括不了的随机事件概率.用事件的频率近似地去表达事件的概率,eg:抛硬币出现正面的频率

## 条件概率

### 条件概率定义

![[Pasted image 20241202143143.png]]

$$P(B|A)= \frac{P(AB)}{P(A)}$$

### 乘法公式

$$P(AB)=P(A)·P(B|A)$$

### 全概率公式

#### 完备事件组

![[Pasted image 20241202153134.png]]

### **全概率公式**（The Law of Total Probability）

是概率论中的一个基本公式，用于将一个复杂事件的概率分解成若干个互不相容事件上的概率求和。

**定义**

假设有一个样本空间 $S$，事件 $A$ 和一组互不相容且完备的事件 $B_1, B_2, \dots, B_n$（即 $\bigcup_{i=1}^n B_i = S$ 且 $B_i \cap B_j = \emptyset$ 当 $i \neq j$）满足：

$$P(B_i) > 0 \quad \forall i \in {1, 2, \dots, n}$$

  

则事件 $A$ 的概率可以表示为：

$$P(A) = \sum_{i=1}^n P(A \cap B_i)$$

根据条件概率的定义，$P(A \cap B_i) = P(A \mid B_i)P(B_i)$，所以公式也可以写成：

$$P(A) = \sum_{i=1}^n P(A \mid B_i)P(B_i)$$

通过全概率公式，可以将复杂概率问题分解成多个简单部分来解决。

### Bayes公式

**贝叶斯公式**（Bayes’ Theorem）是概率论中重要的公式，用于在已知条件概率的情况下计算逆条件概率。它的核心思想是通过先验概率和条件概率来更新对事件发生的概率的认知。

假设事件 $A$ 和 $B$ 满足 $P(B) > 0$，贝叶斯公式可以表示为：

$$

P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}

$$

其中：

• $P(A \mid B)$：在 $B$ 发生的条件下，事件 $A$ 发生的后验概率（Posterior Probability）。
• $P(B \mid A)$：在 $A$ 发生的条件下，事件 $B$ 发生的条件概率。
• $P(A)$：事件 $A$ 的先验概率（Prior Probability）。
• $P(B)$：事件 $B$ 的边际概率（Marginal Probability），可以用全概率公式计算：

$$

P(B) = \sum_{i} P(B \mid A_i)P(A_i)

$$

**理解**

贝叶斯公式的关键是将已知的条件概率 $P(B \mid A)$ 和先验概率 $P(A)$ 转化为逆条件概率 $P(A \mid B)$。它反映了如何根据新证据（$B$）更新对事件（$A$）发生的概率的估计。

**例子**

**例子：疾病诊断**

假设一个测试用于检测某种疾病，定义如下：

• $A$：某人患有这种疾病。
• $B$：测试结果为阳性。

已知数据：

• 该疾病的患病率：$P(A) = 0.01$。
• 测试的灵敏度（准确检出患病者的概率）：$P(B \mid A) = 0.95$。
• 测试的特异性（准确检出未患病者的概率）：$P(B^c \mid A^c) = 0.90$，其中 $B^c$ 表示测试结果为阴性，$A^c$ 表示未患病。

要计算某人测试阳性后，实际患病的概率 $P(A \mid B)$。

**步骤 1：计算 $P(B)$（边际概率）**

$$
P(B) = P(B \mid A)P(A) + P(B \mid A^c)P(A^c)
$$

其中：

• $P(B \mid A^c) = 1 - P(B^c \mid A^c) = 1 - 0.90 = 0.10$
• $P(A^c) = 1 - P(A) = 0.99$

代入数据：

$$

P(B) = 0.95 \times 0.01 + 0.10 \times 0.99 = 0.0095 + 0.099 = 0.1085

$$

  

**步骤 2：代入贝叶斯公式**

$$

P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}

$$

代入数据：

$$

P(A \mid B) = \frac{0.95 \times 0.01}{0.1085} \approx 0.0876

$$

  

**结果**

某人测试阳性后，实际患病的概率为 $8.76percent$。
在概率论和统计学中，**先验概率**和**后验概率**是贝叶斯统计中的两个核心概念，用于描述信息更新前后的概率。

####  **先验概率（Prior Probability）**

**定义**：先验概率是基于已有知识或经验，对某个事件发生的初始估计概率。

• 它表示在没有引入额外证据之前，对事件可能性的一种主观判断或客观估计。
• 通常来源于历史数据、经验或假设。
• 在贝叶斯公式中，用 $P(A)$ 表示，表示在观察证据 $B$ 之前，事件 $A$ 的概率。

**例子**

1. **医学领域**：

• 某种疾病的患病率是 $1%$。这是基于历史数据计算得到的先验概率。

• $P(A) = 0.01$，这里 $A$ 是“患病”的事件。

2. **经济预测**：

• 根据过去的市场行为，预计某支股票价格上涨的概率是 70%，这就是先验概率。

#### **后验概率（Posterior Probability）**

**定义**：后验概率是在观察到额外信息或证据后，对事件发生概率的更新。

• 它表示结合新的证据后，重新评估某事件的可能性。
• 在贝叶斯公式中，用 $P(A \mid B)$ 表示，表示在证据 $B$ 出现后，事件 $A$ 的概率。
• 后验概率是对先验概率的调整，结合了新的数据或信息。

**例子**

1. **医学领域**：

• 某人进行了疾病检测，测试结果为阳性。

• 根据贝叶斯公式重新计算的概率 $P(A \mid B)$，表示在测试阳性这一新证据下，该人实际患病的概率。

2. **经济预测**：

• 如果观察到股市整体走势上升，更新后某支股票价格上涨的概率变为 85%。这就是后验概率。

## 事件的独立性

在概率论中，**事件的独立性**是描述两个或多个事件之间是否存在关联的一种特性。如果事件之间没有任何关联，即一个事件的发生不会影响另一个事件发生的概率，则这些事件被称为独立事件。

### **定义**

两个事件 $A$ 和 $B$ 被称为独立事件，当且仅当：

$$

P(A \cap B) = P(A)P(B)

$$

**解释**：

• $P(A \cap B)$ 表示事件 $A$ 和事件 $B$ 同时发生的概率。
• 如果 $P(A \cap B)$ 等于 $P(A)$ 和 $P(B)$ 的乘积，则 $A$ 和 $B$ 的发生是完全独立的，没有任何交互或依赖关系。

### **条件概率定义**

另一个等价的定义是基于条件概率：

$$
P(A \mid B) = P(A)
$$

或

$$
P(B \mid A) = P(B)
$$

**解释**：事件 $A$ 的发生概率不因事件 $B$ 的发生与否而改变，反之亦然。  

**举例**

1. **投掷硬币**

• 第一次投掷硬币是正面（事件 $A$）。
• 第二次投掷硬币是正面（事件 $B$）。
• 因为每次投掷硬币的结果互不影响，所以 $A$ 和 $B$ 是独立事件。

验证：

• $P(A) = 0.5$, $P(B) = 0.5$。
• $P(A \cap B) = P(\text{第一次正面且第二次正面}) = 0.5 \times 0.5 = 0.25$。
• 满足独立性条件：$P(A \cap B) = P(A)P(B)$。

2. **掷骰子**

• 掷一次骰子，事件 $A$ 是掷出偶数，事件 $B$ 是掷出的点数大于 3。
• 偶数有 ${2, 4, 6}$，点数大于 3 的有 ${4, 5, 6}$，同时满足 $A$ 和 $B$ 的是 ${4, 6}$。
• $P(A) = \frac{3}{6} = 0.5$, $P(B) = \frac{3}{6} = 0.5$。
• $P(A \cap B) = \frac{2}{6} = \frac{1}{3}$。

• 验证：$P(A \cap B) \neq P(A)P(B)$，因此 $A$ 和 $B$ 不是独立事件  

### **多个事件的独立性**  

如果有多个事件 $A_1, A_2, \dots, A_n$，这些事件是**相互独立的**，需满足以下条件：

1. 任意两个事件是独立的，即对于任意 $i \neq j$：

$$

P(A_i \cap A_j) = P(A_i)P(A_j)

$$

2. 任意多个事件的联合概率等于每个事件概率的乘积，例如对于三个事件 $A_1, A_2, A_3$：

$$

P(A_1 \cap A_2 \cap A_3) = P(A_1)P(A_2)P(A_3)

$$

**注意：**

• **两两独立不等于相互独立**：即使任意两个事件之间独立，也不一定意味着所有事件之间相互独立。

### **独立性与不独立的对比**

**特性**                   **独立事件**                                                  **不独立事件**

定义                  $P(A \cap B) = P(A)P(B)$                        $P(A \cap B) \neq P(A)P(B)$

条件概率            $P(A \mid B) = P(A)$                           $P(A \mid B) \neq P(A)$

影响            一个事件发生不影响另一个事件          一个事件发生可能影响另一个事件

**独立性的重要性**

1. **简化计算**：在多个事件独立的情况下，可以通过概率的乘法规则快速计算联合概率。

• 如 $P(A_1 \cap A_2 \cap A_3) = P(A_1)P(A_2)P(A_3)$。

2. **建模基础**：独立性假设是许多概率模型（如朴素贝叶斯分类器）的核心前提。

3. **统计学应用**：样本的独立性是许多统计推断方法的前提，如参数估计和假设检验。



# 二. 随机变量

## 1. 随机变量的定义

==设$(Ω, F, P)$是概率空间,$X=X(e)$是定义在$Ω$上的实函数.如果对任意实数$x$，$\{e:X(e) \leq x\} \in F$ 则称$X(e)$是$F$上的随机变量.==

### (1)$(Ω, F, P)$是概率空间

#### 1). $Ω$(样本空间)

• $Ω$是一个集合，包含所有可能的实验结果。

• 例如：

• 如果抛一枚硬币，$Ω = {\text{正面}, \text{反面}}$。
• 如果掷一颗骰子，$Ω = {1, 2, 3, 4, 5, 6}$。
• $Ω$表示所有可能发生的结果，是概率论的基础。

#### **2). $F$（事件的集合/$σ$-代数）**

• $F$是$Ω$的一个子集，表示可以“度量概率”的事件集合。
• 一个事件是样本空间中的一些特定结果的集合。

• 例如：
• 对于硬币，事件可以是“正面朝上”，即$F = {\text{正面}}$，或“反面朝上”，即$F = {\text{反面}}$。
• 对于骰子，事件可以是“掷出偶数”，即$F = {2, 4, 6}$。
• 数学上，$F$需要满足某些条件（如包含全集、闭合性等），初学时可以简单理解为“描述感兴趣事件的集合”。

#### **3). $P$（概率测度）**

• $P$是一个函数，用来为$F$中的每个事件分配概率，描述事件发生的可能性。
• $P$需要满足以下性质：
1. **非负性**：对任意事件$A \in F$，$P(A) \geq 0$。
2. **规范性**：$P(Ω) = 1$（样本空间的概率总和为1）。
3. **可加性**：如果$A_1, A_2, \dots$是互不重叠的事件，则有：

$$P(A_1 \cup A_2 \cup \dots) = P(A_1) + P(A_2) + \dots$$

例如：

• 抛一枚均匀的硬币，概率分布是：
• $P({\text{正面}}) = 0.5$
• $P({\text{反面}}) = 0.5$
• 掷一颗均匀骰子，概率分布是：
• $P({1}) = \frac{1}{6}$
• $P({2, 4, 6}) = \frac{1}{2}$（偶数的概率）

### (2)$X=X(e)$是定义在$Ω$上的实函数

• $X$表示随机变量，它是一个函数，把样本空间中的元素（$e$，即样本）映射到实数空间。
• 换句话说，随机变量把复杂的实验结果（$e$）用一个实数来表示。

• 例如，抛硬币：
• $Ω = {\text{正面}, \text{反面}}$。
• 定义随机变量$X$为：“正面记作1，反面记作0”。这就是一个函数映射：
• 如果$e = \text{正面}$，$X(e) = 1$。
• 如果$e = \text{反面}$，$X(e) = 0$。

### (3). 如果对任意实数$x$，$\{e:X(e) \leq x\} \in F$

这句话的意思是：

• 随机变量$X$的值**小于等于某个实数$x$的所有样本事件组成的集合${e : X(e) \leq x}$，必须是事件集合$F$中的一个元素。

**通俗解释**

• ${e : X(e) \leq x}$是一个集合，表示“实验结果$e$”中，哪些事件使得随机变量$X$的值小于等于$x$。
• 这个集合必须是“可测的”，也就是它必须属于$F$，这样概率$P$才能被定义。

**举例说明**

1. 假设我们掷一颗骰子，样本空间$Ω = {1, 2, 3, 4, 5, 6}$。
2. 定义随机变量$X(e) = e$，表示掷出的点数。
3. 如果我们关心“掷出的点数小于等于3”的事件集合${e : X(e) \leq 3}$，那么这个集合就是${1, 2, 3}$。
4. 这个集合${1, 2, 3}$需要属于$F$，我们才能给它赋一个概率，比如$P({1, 2, 3}) = \frac{3}{6} = 0.5$。

这表明，随机变量$X$的定义必须依赖于$F$，这样$X$的值和概率才有意义。

### (4)则称$X(e)$是$F$上的随机变量

**这句话的意义**

只要随机变量$X$满足以下条件：

1. 它是从$Ω$到实数的映射；
2. 对任何实数$x$，集合${e : X(e) \leq x}$都在事件集合$F$中；

我们就可以说：

• $X$是一个随机变量；
• 它是定义在事件集合$F$上的，也就是$F$保证了$X$的取值可以被描述并赋予概率。

**再通俗一点解释**

随机变量$X$的定义要求：

1. 它能把样本空间中的结果（例如骰子的点数）映射为一个实数；
2. 它的分布（例如“点数小于等于3”）可以用$F$中的事件描述，从而分配概率。

**更直观的例子**

• 假设你有一个随机变量$X$，表示“掷骰子的点数”。
• 如果$F$是一个非常简单的集合，例如${空集, Ω}$，那么它不能描述复杂的事件（比如“点数小于等于3”）。
• 只有当$F$包含了所有可能的子集（例如${1, 2, 3}$这样的事件集合），我们才能说$X$是定义在$F$上的随机变量。

## 2. 随机变量的分类

### 累积分布函数（CDF）

累积分布函数$F(x)$定义为随机变量$X$取值小于或等于某实数$x$的概率：

$$
F(x) = P(e : X(e) \leq x)
$$

这里$x$可以取任何实数值，从$-\infty$到$\infty$。

**主要性质**

1. **右连续性**：$F(x)$是右连续的，意味着在$x$的任意右侧点，函数值$F(x)$趋向于该点的函数值。换句话说，当我们从左边逼近$x$时，$F(x)$的值不会突变。
2. **取值范围**：$0 \leq F(x) \leq 1$。这表示$F(x)$作为概率，其值必须在0和1之间，包括0和1。
3. **概率计算**：$P(x_1 < X \leq x_2) = F(x_2) - F(x_1)$。这个性质用于计算随机变量$X$取值在某个区间$(x_1, x_2]$的概率。
4. **增函数性**：$F(x)$是一个非递减函数。这意味着如果$x_1 \leq x_2$，那么$F(x_1) \leq F(x_2)$。这反映了随机变量$X$取值越大，小于或等于这个值的概率不会减小。

### (1)离散型随机变量

#### **1).离散型随机变量定义**

只取有限个数值或可列无穷多个值

• 例如：

• 抛硬币：$X$表示正面朝上的次数，可能取值为$0, 1$。
• 掷骰子：$X$表示掷出的点数，可能取值为$1, 2, 3, 4, 5, 6$。

#### **2). 概率分布的定义**

离散型随机变量的概率分布描述了$X$取每一个可能值时的概率。用数学表示为：
$$
P(X = x_k) = p_k, \quad k = 1, 2, \dots
$$
这里：
• $x_k$表示$X$的第$k$个可能取值。
• $p_k$表示$X$取值为$x_k$的概率。

**举例**  

掷骰子的随机变量$X$可能取值$x_1 = 1, x_2 = 2, \dots, x_6 = 6$，并且每个值的概率都是$\frac{1}{6}$。所以：
$$
P(X = 1) = P(X = 2) = \dots = P(X = 6) = \frac{1}{6}
$$

#### **3). 分布律的两个性质**

分布律满足以下两个基本条件（由概率的性质决定）：

1. **非负性**：$p_k \geq 0$，这表示概率不能为负。
• 比如，掷骰子时，任何点数的概率都必须是非负的。

2. **归一性**：所有可能取值的概率之和等于$1$，即：
$$
\sum_{k=1}^\infty p_k = 1
$$
• 这表示随机变量的所有可能取值覆盖了整个样本空间，因此它们的总概率必须是$1$。
• 举例：掷骰子时，所有点数的概率总和是：
$$
P(X=1) + P(X=2) + \dots + P(X=6) = \frac{1}{6} + \frac{1}{6} + \dots + \frac{1}{6} = 1
$$

### (2)连续型随机变量

#### **1).连续型随机变量定义**

从原样本空间到新样本空间的映射是 某一个范围是一段(或几段)实线(也可能是整个坐标轴),随机变量可以取某一区间中的任一数.

• 定义中提到：
$$

F(x) = \int_{-\infty}^x f(t) , dt

$$

这里：
• $F(x)$是**累积分布函数（CDF）**，表示随机变量$X$小于或等于$x$的概率：$F(x) = P(X \leq x)$。
• $f(x)$是**概率密度函数（PDF）**，是一个非负、可积的函数。

**关键点**

• 如果随机变量$X$有一个满足上述公式的密度函数$f(x)$，就称$X$为**连续型随机变量**。
• 累积分布函数$F(x)$是由密度函数$f(x)$通过积分得到的。

#### **2). 概率密度函数$f(x)$的含义**

• **密度函数$f(x)$并不是概率本身，而是概率的密度**。它满足：
$$

P(a < X \leq b) = \int_a^b f(x) , dx

$$

这表示随机变量$X$的值在区间$(a, b]$中的概率是$f(x)$在该区间的积分值。
• 换句话说，密度函数描述了随机变量在不同点附近取值的“可能性强度”。

**例子**

假设$f(x)$是均匀分布在$[0,1]$上的密度函数：
$$

f(x) =

\begin{cases}

1, & 0 \leq x \leq 1 \\

0, & \text{otherwise}

\end{cases}

$$

那么：

1. $P(0.2 \leq X \leq 0.8) = \int_{0.2}^{0.8} f(x) , dx = \int_{0.2}^{0.8} 1 , dx = 0.8 - 0.2 = 0.6$。
2. $P(X \leq 0.5) = \int_{-\infty}^{0.5} f(x) , dx = \int_{0}^{0.5} 1 , dx = 0.5$。

#### **3.) 连续型随机变量的性质**

1. **密度函数$f(x)$的非负性**：
$$
f(x) \geq 0
$$

表示在任何取值点附近，概率密度都不能为负。

2. **密度函数的归一性**：
$$
\int_{-\infty}^{+\infty} f(x) , dx = 1
$$

这是概率的总和等于1的要求，即随机变量必定在某个地方取值。

3. **累积分布函数$F(x)$的连续性**：
$F(x)$是一个连续且非减的函数，表示概率的累积不会有跳跃。

 4. 概率计算
$$
P(x_1 < X \leq x_2) = \int_{x_1}^{x_2} f(x) , dx
$$

这说明可以通过积分计算随机变量$X$在区间$(x_1, x_2]$内的概率。


5. 局部概率的极限性

对于任意单点$x$，随机变量$X$取值恰好为$x$的概率为0：
$$

P(X = x) = \int_x^x f(t) , dt = 0

$$
连续型随机变量的概率由区间长度决定，单点没有概率。

6. 平均值与方差

概率密度函数还用于计算随机变量的期望和方差：
• 期望：
$$

E(X) = \int_{-\infty}^{+\infty} x f(x) , dx

$$
• 方差：
$$

\text{Var}(X) = \int_{-\infty}^{+\infty} (x - E(X))^2 f(x) , dx

$$

### (3)常见分布

#### 1)离散型随机变量的概率分布

| 分布类型  | 分布描述                                         |
| ----- | -------------------------------------------- |
| 0-1分布 | $P(X=1) = p, \; P(X=0) = q$，其中 $q = 1 - p$   |
| 二项分布  | $P(X=k) = C_n^k p^k q^{n-k}$，其中 $q = 1 - p$  |
| 泊松分布  | $P(X=k) = \frac{\lambda^k}{k!} e^{-\lambda}$ |

#### 2)连续型随机变量的概率分布

| 分布类型  | 概率密度函数 $f(x)$                                              |
|-----------|------------------------------------------------------------------|
| 均匀分布  | $f(x) = \begin{cases} \frac{1}{b-a}, & a < x < b \\ 0, & \text{其他} \end{cases}$ |
| 正态分布  | $f(x) = \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ |
| 指数分布  | $f(x) = \begin{cases} \lambda e^{-\lambda x}, & x \geq 0 \\ 0, & x < 0 \end{cases}$ |

## 3. $\delta$函数（Dirac Delta函数）

### **(1). $\delta$函数的定义**

$\delta$函数并不是一个传统意义上的函数，而是一个广义函数或分布（distribution）。它的定义满足以下性质：

**定义性质**

1. $\delta(x)$在$x=0$时取无限值，在$x\neq 0$时取值为$0$：
$$
\delta(x) =
\begin{cases}
0, & x \neq 0 \\
\infty, & x = 0
\end{cases}
$$
这意味着$\delta(x)$只有在$x=0$处起作用。

2. $\delta(x)$的积分值为$1$：
$$
\int_{-\infty}^{+\infty} \delta(x) , dx = 1
$$

这表示$\delta$函数的总“权重”分布在$x=0$处。

$\delta$函数的直观理解

$\delta(x)$可以被看作是一个无限窄但又无限高的“脉冲”，它的面积固定为$1$。它通常用来描述在某个特定点上发生的事件.  

### (2). $\delta$函数的性质

$\delta$函数有一些重要性质：

1. **加权采样性质**：

对于任意函数$f(x)$：
$$

\int_{-\infty}^{+\infty} f(x)\delta(x) , dx = f(0)

$$

这表示$\delta(x)$从$f(x)$中“采样”出了$x=0$处的值。

2. **平移性质**：
如果$\delta$函数平移到$x=T$的位置：

$$

\int_{-\infty}^{+\infty} f(x)\delta(x-T) , dx = f(T)

$$

这意味着$\delta(x-T)$会从$f(x)$中“采样”出$x=T$处的值。

### **(3). 离散型随机变量的概率密度表示**

对于离散型随机变量，我们可以用$\delta$函数来表示它的概率密度。假设随机变量$X$的可能取值为$x_1, x_2, \dots$，每个取值的概率为$P(X = x_k)$，那么它的概率密度函数可以表示为：

$$

f_X(x) = \sum_{k=1}^\infty P(X = x_k) \delta(x - x_k)

$$

这里：

• $\delta(x - x_k)$表示随机变量$X$在$x_k$处的“脉冲”。
• 每个$\delta(x - x_k)$的权重是$P(X = x_k)$，即$X$取值为$x_k$的概率。

**理解**

1. $f_X(x)$在离散点$x_k$处具有概率密度，其大小为$P(X = x_k)$。
2. 在非离散点处，$f_X(x)$为$0$。

### **(4). 举例**

假设随机变量$X$表示一个骰子的掷出点数（$1, 2, 3, 4, 5, 6$），并且：
$$

P(X = k) = \frac{1}{6}, \quad k = 1, 2, 3, 4, 5, 6

$$

那么它的概率密度函数可以写成：
$$

f_X(x) = \frac{1}{6} \delta(x - 1) + \frac{1}{6} \delta(x - 2) + \frac{1}{6} \delta(x - 3) + \dots + \frac{1}{6} \delta(x - 6)

$$

这表示随机变量$X$在每个点（$1, 2, \dots, 6$）上有$\frac{1}{6}$的概率密度，而其他点概率密度为$0$。

### (5)$\delta$函数的意义

**1. 描述“瞬时作用”或“点性质”的工具**

$\delta$函数可以用来描述在某一点上发生的作用，而不考虑其他地方的值。例如：

• **物理中的冲击力**：如果一个非常大的力作用在一个极短的时间间隔上，传统函数无法很好地描述这样的“瞬时冲击”。用$\delta(t)$，我们可以描述这种“在某时刻发生的无限强作用”。

• **概率论中的离散型随机变量**：对于离散型随机变量，其概率密度集中在一些离散的点上，例如$P(X = x_k)$。用$\delta$函数，可以精确地表示这些离散点上的概率密度。

**2. 连接离散和连续的桥梁**

在数学和工程中，$\delta$函数是一种**桥梁**，把离散系统和连续系统联系起来。例如：

• **离散型随机变量的概率密度表示**：
离散型随机变量的概率密度可以用$\delta$函数表示：

$$

f_X(x) = \sum_{k=1}^\infty P(X = x_k) \delta(x - x_k)

$$

这将离散的概率分布转化为了连续的数学表示。

**3. 计算和采样的工具**

• **采样特性**：

$$

\int_{-\infty}^\infty f(x) \delta(x - T) , dx = f(T)

$$

这意味着，$\delta(x - T)$会“提取”函数$f(x)$在$x = T$处的值。

## 4.**随机变量的函数变换**

### **(1). 问题背景**

• 给定随机变量 $X$ 的概率分布 $f_X(x)$ 或累积分布函数 $F_X(x)$。
• 给定 $Y = g(X)$，我们希望得到随机变量 $Y$ 的概率密度函数 $f_Y(y)$ 或分布函数 $F_Y(y)$。

例如：如果 $X$ 是均匀分布在 $[0, 2\pi]$ 上的随机变量，我们可以求 $Y = \cos(X)$ 的概率密度函数。

### **(2). 单调函数变换**

如果 $g(x)$ 是单调的可导函数，分布的推导会变得较为简单。

#### **1) $g(x)$ 是单调递增函数**

假设 $g(x)$ 是单调递增函数，其反函数为 $x = g^{-1}(y)$。此时：
$$

F_Y(y) = P(Y \leq y) = P(X \leq g^{-1}(y)) = F_X(g^{-1}(y))

$$

两边对 $y$ 求导，可以得到 $Y$ 的概率密度函数：

$$

f_Y(y) = f_X(g^{-1}(y)) \left| \frac{dx}{dy} \right| = f_X(g^{-1}(y)) \left| \frac{1}{g’(x)} \right|

$$

#### **2) $g(x)$ 是单调递减函数**

如果 $g(x)$ 是单调递减函数，分布函数变为：

$$
F_Y(y) = P(Y \leq y) = P(X \geq g^{-1}(y)) = 1 - F_X(g^{-1}(y))
$$

同样，对 $y$ 求导：
$$

f_Y(y) = -f_X(g^{-1}(y)) \frac{d}{dy} g^{-1}(y) = f_X(g^{-1}(y)) \left| \frac{dx}{dy} \right|

$$

#### **3) 统一公式**

无论 $g(x)$ 是单调递增还是单调递减函数，我们统一表示为：
$$
f_Y(y) = f_X(x) \left| J \right|, \quad J = \frac{dx}{dy} \text{ 是雅可比行列式}
$$

### **(3). 非单调函数变换**

如果 $g(x)$ 不是单调函数，可能会出现一个 $y$ 值对应多个 $x$ 值的情况（例如 $\cos(x)$ 是周期函数）。此时需要对所有满足 $g(x) = y$ 的 $x$ 取值进行累加。

#### **1) 若一个 $y$ 对应两个 $x$ 值 $x_1$ 和 $x_2$**

密度函数为：

$$
f_Y(y) = f_X(x_1) \left| \frac{dx_1}{dy} \right| + f_X(x_2) \left| \frac{dx_2}{dy} \right|
$$

#### **2) 若一个 $y$ 对应 $n$ 个 $x$ 值**

密度函数推广为：

$$
f_Y(y) = \sum_{i=1}^n f_X(x_i) \left| \frac{dx_i}{dy} \right|
$$

### **(4). 例子：$Y = \cos(X)$ 的概率密度**

假设 $X \sim U[0, 2\pi]$，即 $X$ 在 $[0, 2\pi]$ 上均匀分布，概率密度函数为：

$$

f_X(x) = \frac{1}{2\pi}, \quad 0 \leq x \leq 2\pi

$$

求 $Y = \cos(X)$ 的概率密度。

**分析：**

• $\cos(X)$ 在 $[0, 2\pi]$ 上是非单调函数，每个 $Y = y$ 值对应两个 $X$ 值。
• 在 $[0, 2\pi]$ 上，$Y = \cos(X)$ 的取值范围为 $[-1, 1]$。

**计算：**

设 $x_1 = \arccos(y)$ 和 $x_2 = 2\pi - \arccos(y)$，则：
$$

f_Y(y) = f_X(x_1) \left| \frac{dx_1}{dy} \right| + f_X(x_2) \left| \frac{dx_2}{dy} \right|

$$

因为 $f_X(x) = \frac{1}{2\pi}$ 且 $\frac{dx_1}{dy} = \frac{-1}{\sqrt{1-y^2}}$，所以：
$$
f_Y(y) = \frac{1}{2\pi} \frac{1}{\sqrt{1-y^2}} + \frac{1}{2\pi} \frac{1}{\sqrt{1-y^2}}
$$
即：
$$
f_Y(y) = \frac{1}{\pi \sqrt{1-y^2}}, \quad -1 \leq y \leq 1
$$

这是 $Y = \cos(X)$ 的概率密度函数。

## 5. n维随机变量

### (1)$n$维随机变量定义

• $X = (X_1, X_2, \dots, X_n)$是一个$n$维随机变量。
• 它是由$n$个随机变量$(X_1, X_2, \dots, X_n)$组成的向量。
• 每个随机变量$X_i$都定义在概率空间$(\Omega, F, P)$上，并取值于实数域$\mathbb{R}$。

**含义**

• $n$维随机变量可以理解为一个试验的$n$个相关结果。例如：
• 掷两颗骰子：$(X_1, X_2)$分别表示两颗骰子的点数。
• 天气分析：$(X_1, X_2, X_3)$可以分别表示某地的温度、湿度和风速。

**数学描述**

• 事件${X_1(e) \leq x_1, X_2(e) \leq x_2, \dots, X_n(e) \leq x_n}$表示随机变量在给定范围内的联合事件。
• 如果该事件属于$F$（可测事件），则称$X$是$n$维随机变量。

### **(2). 联合分布函数**

**定义**

$n$维随机变量$X = (X_1, X_2, \dots, X_n)$的**联合分布函数**$F_X(x)$定义为：

$$

F_X(x) = F(x_1, x_2, \dots, x_n) = P(X_1 \leq x_1, X_2 \leq x_2, \dots, X_n \leq x_n)

$$

  

**含义**

  

• 联合分布函数表示$n$维随机变量在各个分量$X_1, X_2, \dots, X_n$取值分别小于等于$x_1, x_2, \dots, x_n$的概率。

• 它是描述$n$维随机变量联合分布的基本工具。

  

**性质**

  

1. $F_X(x)$是一个非减函数：

• 如果$x_1 \leq x_1’$，$x_2 \leq x_2’$，$\dots$，则$F(x_1, x_2, \dots, x_n) \leq F(x_1’, x_2’, \dots, x_n’)$。

2. $F_X(x)$的取值范围是$[0, 1]$：

• 概率不会超过1，且非负。

3. 如果所有分量趋向于正无穷，则$F_X(x) \to 1$：

• $P(X_1 \leq \infty, X_2 \leq \infty, \dots) = 1$。

  

**3. 联合分布的意义**

  

联合分布函数刻画了多维随机变量的联合行为：

• 如果我们仅知道各个随机变量$X_1, X_2, \dots, X_n$的单独分布（边缘分布），无法描述它们之间的关联性。

• 联合分布函数可以描述随机变量之间的相关性。例如：

• $X_1$和$X_2$是否独立。

• $X_1$和$X_2$取某些值时的联合概率。

  

**4. 举例**

  

**(1) 二维随机变量**

  

假设$(X_1, X_2)$表示两颗骰子的点数，每个点数范围是$1, 2, 3, 4, 5, 6$。它的联合分布函数为：

$$

F(x_1, x_2) = P(X_1 \leq x_1, X_2 \leq x_2)

$$

• 当$x_1 = 3, x_2 = 4$时，$F(3, 4)$表示：

$$

P(X_1 \leq 3, X_2 \leq 4) = P(\text{第一颗骰子点数$\leq 3$，且第二颗骰子点数$\leq 4$})

$$

  

**(2) 独立随机变量**

  

如果$X_1$和$X_2$是独立的，则联合分布函数可以分解为：

$$

F(x_1, x_2) = F_{X_1}(x_1) \cdot F_{X_2}(x_2)

$$

这表示两颗骰子的点数互不影响。

  

**总结**

  

1. $n$维随机变量由$n$个随机变量组成，可以描述多维随机现象。

2. 联合分布函数$F_X(x)$用于描述这些随机变量的联合概率。

3. 联合分布函数是研究多维随机变量分布和相关性的基础工具。

  

如果某部分还不清楚，可以继续深入解释！